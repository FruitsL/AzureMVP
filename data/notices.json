[
  {
    "title": "Blob Storage íŒŒì¼ ì—…ë¡œë“œ ê·œì¹™ ì¶”ê°€",
    "desc": "Blob Storage íŒŒì¼ ì—…ë¡œë“œ ê·œì¹™ ë³€ê²½",
    "lang": "python",
    "code_changes": [
      {
        "before": "- name: Upload changed files to Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ ì¤‘...\"\n      CHANGED_FILES=$(git diff --name-only HEAD^ HEAD)\n\n      for file in $CHANGED_FILES; do\n        if [[ \"$file\" == .git/* || \"$file\" == .git\\\\* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        if [ -f \"$file\" ]; then\n          echo \"ì—…ë¡œë“œ: $file\"\n          az storage blob upload \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --file \"$file\" \\\n            --name \"$file\" \\\n            --overwrite true\n        else\n          echo \"ìŠ¤í‚µ: $file (íŒŒì¼ ì—†ìŒ ë˜ëŠ” ì‚­ì œë¨)\"\n        fi\n      done\n",
        "after": "- name: Sync changed files with Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ ì¤‘...\"\n      CHANGED_FILES=$(git diff --name-only HEAD^ HEAD)\n\n      for file in $CHANGED_FILES; do\n        if [[ \"$file\" == .git/* || \"$file\" == .git\\\\* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        if [ -f \"$file\" ]; then\n          echo \"ì—…ë¡œë“œ: $file\"\n          az storage blob upload \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --file \"$file\" \\\n            --name \"$file\" \\\n            --overwrite true\n        else\n          echo \"ì‚­ì œ: $file\"\n          az storage blob delete \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --name \"$file\" \\\n            --only-if-unmodified\n        fi\n      done\n"
      },
      {
        "before": "- name: Upload all files to Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ì €ì¥ì†Œ ì „ì²´ íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘...\"\n      find . -type f | while read file; do\n        # .git í´ë” ì œì™¸\n        if [[ \"$file\" == ./.git/* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        echo \"ì—…ë¡œë“œ: $file\"\n        az storage blob upload \\\n          --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n          --account-key \"$AZURE_STORAGE_KEY\" \\\n          --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n          --file \"$file\" \\\n          --name \"$file\" \\\n          --overwrite true\n      done\n",
        "after": "- name: Sync changed files with Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ ì¤‘...\"\n      CHANGED_FILES=$(git diff --name-status HEAD^ HEAD)\n\n      while read -r status file; do\n        # .git í´ë”ëŠ” ë¬´ì‹œ\n        if [[ \"$file\" == .git/* || \"$file\" == .git\\\\* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        if [[ \"$status\" == \"A\" || \"$status\" == \"M\" ]]; then\n          # ì¶”ê°€/ìˆ˜ì •ëœ íŒŒì¼ë§Œ ì—…ë¡œë“œ\n          if [ -f \"$file\" ]; then\n            echo \"ì—…ë¡œë“œ: $file\"\n            az storage blob upload \\\n              --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n              --account-key \"$AZURE_STORAGE_KEY\" \\\n              --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n              --file \"$file\" \\\n              --name \"$file\" \\\n              --overwrite true\n          fi\n        elif [[ \"$status\" == \"D\" ]]; then\n          # ì‚­ì œëœ íŒŒì¼ì€ blobì—ì„œë„ ì‚­ì œ\n          echo \"ì‚­ì œ: $file\"\n          az storage blob delete \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --name \"$file\" \\\n            --only-if-unmodified\n        fi\n      done <<< \"$CHANGED_FILES\"\n"
      }
    ],
    "timestamp": "2025-09-30 16:44:44",
    "ai_check_results_by_env": {
      "github-web|web-code-index": {
        "container": "github-web",
        "index": "web-code-index",
        "timestamp": "2025-09-30 16:52:45",
        "results": [
          {
            "change_index": 1,
            "before_code": "- name: Upload changed files to Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ ì¤‘...\"\n      CHANGED_FILES=$(git diff --name-only HEAD^ HEAD)\n\n      for file in $CHANGED_FILES; do\n        if [[ \"$file\" == .git/* || \"$file\" == .git\\\\* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        if [ -f \"$file\" ]; then\n          echo \"ì—…ë¡œë“œ: $file\"\n          az storage blob upload \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --file \"$file\" \\\n            --name \"$file\" \\\n            --overwrite true\n        else\n          echo \"ìŠ¤í‚µ: $file (íŒŒì¼ ì—†ìŒ ë˜ëŠ” ì‚­ì œë¨)\"\n        fi\n      done",
            "after_code": "- name: Sync changed files with Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ ì¤‘...\"\n      CHANGED_FILES=$(git diff --name-only HEAD^ HEAD)\n\n      for file in $CHANGED_FILES; do\n        if [[ \"$file\" == .git/* || \"$file\" == .git\\\\* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        if [ -f \"$file\" ]; then\n          echo \"ì—…ë¡œë“œ: $file\"\n          az storage blob upload \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --file \"$file\" \\\n            --name \"$file\" \\\n            --overwrite true\n        else\n          echo \"ì‚­ì œ: $file\"\n          az storage blob delete \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --name \"$file\" \\\n            --only-if-unmodified\n        fi\n      done",
            "ai_analysis": "ì•„ë˜ëŠ” ìš”ì²­í•˜ì‹  ë³€ê²½ ì „/í›„ ì½”ë“œ íŒ¨í„´ì— ëŒ€í•œ ì² ì €í•œ ê²€ì¦ ë° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.\n\n---\n\n## 1ë‹¨ê³„: ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ ê²€ìƒ‰ (ìœ ì—°í•œ ë§¤ì¹­)\n\n- **ê²€ìƒ‰ ëŒ€ìƒ íŒ¨í„´**:  \n  ë³€ê²½ ì „ ì½”ë“œ í•µì‹¬ì€  \n  1) git diffë¡œ ë³€ê²½ íŒŒì¼ ëª©ë¡ì„ ì¶”ì¶œ  \n  2) .git í´ë” ì œì™¸  \n  3) íŒŒì¼ ì¡´ì¬ ì‹œ Azure Blob Storageì— ì—…ë¡œë“œ  \n  4) íŒŒì¼ì´ ì—†ìœ¼ë©´(ì‚­ì œ ë“±) ì—…ë¡œë“œí•˜ì§€ ì•Šê³  ìŠ¤í‚µ  \n  ì˜ êµ¬ì¡°ë¥¼ ê°€ì§„ ì‰˜ ìŠ¤í¬ë¦½íŠ¸ í˜•íƒœ GitHub Action ë‚´ `inlineScript` ë¶€ë¶„ì…ë‹ˆë‹¤.\n\n- **ê²€ìƒ‰ ê²°ê³¼**:  \n  - `azure-deploy.yml` ë˜ëŠ” `.github/workflows/` ê²½ë¡œ í•˜ìœ„ GitHub Actions ì›Œí¬í”Œë¡œìš° íŒŒì¼ ë‚´ì—ì„œ  \n  - [doc2], [doc3], [doc4], [doc5] ë‚´ìš© ì¤‘ ìœ ì‚¬ ë¡œì§ ì¼ë¶€ í™•ì¸ë¨. íŠ¹íˆ [doc2], [doc3]ì—ì„œ Azure Blob Storage ì—…ë¡œë“œ ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸ê°€ ì¡´ì¬í•˜ì§€ë§Œ, ë³€ê²½ ì „ ì½”ë“œì™€ ì™„ì „íˆ ì¼ì¹˜í•˜ëŠ” ë¸”ë¡ì€ ì—†ìŒ.  \n  - ë‹¤ë§Œ, [doc2]ì—ì„  ê¸°ì¡´ ì—…ë¡œë“œ ì‹œ MD5 ë¹„êµ í›„ ë³€ê²½ëœ íŒŒì¼ë§Œ ì—…ë¡œë“œí•˜ëŠ” ë¡œì§ì´ í¬í•¨ë˜ì–´ ìˆì–´, íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í›„ ì—…ë¡œë“œí•˜ëŠ” ë°©ì‹ê³¼ ìœ ì‚¬í•˜ë‚˜ git diffë¥¼ ì´ìš©í•œ ë³€ê²½ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì‚­ì œ íŒŒì¼ ì²˜ë¦¬ ë¡œì§ì€ ì—†ìŒ.  \n  - [doc4], [doc5]ëŠ” CI/CD íŒŒì´í”„ë¼ì¸ ë° AI ì„œë¹„ìŠ¤ ê´€ë ¨ ì„¤ëª…ì´ë©°, êµ¬ì²´ì ì¸ ìŠ¤í¬ë¦½íŠ¸ ì½”ë“œ ë¸”ë¡ì€ ì¼ë¶€ë§Œ ì¡´ì¬.  \n  - ë”°ë¼ì„œ **ë³€ê²½ ì „ ì½”ë“œì™€ ì™„ì „íˆ ë˜ëŠ” ìœ ì—°í•˜ê²Œ ë§¤ì¹­ë˜ëŠ” ì½”ë“œ ë¸”ë¡ì€ í˜„ì¬ ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ì—ì„œ ë°œê²¬ë˜ì§€ ì•ŠìŒ**.\n\n- **ìš”ì•½**:  \n  - ë³€ê²½ ì „ ì½”ë“œì˜ í•µì‹¬ íŒ¨í„´(íŠ¹íˆ `git diff`ë¡œ ë³€ê²½ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ í›„ ì—…ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸)ì™€ ì™„ì „íˆ ì¼ì¹˜í•˜ê±°ë‚˜ ìœ ì‚¬í•œ êµ¬í˜„ì€ ì¸ë±ìŠ¤ ë‚´ì— ë°œê²¬ë˜ì§€ ì•ŠìŒ.  \n  - ë³€ìˆ˜ëª…, í•¨ìˆ˜ëª…, ì£¼ì„ ì°¨ì´, ê³µë°± ì°¨ì´ ë“±ì„ ê³ ë ¤í•´ë„ ìœ ì‚¬ íŒ¨í„´ ì—†ìŒ.\n\n---\n\n## 2ë‹¨ê³„: ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ ê²€ì¦ (ë³€ê²½ ì „ ì½”ë“œ ë°œê²¬ ì‹œë§Œ)\n\n- ë³€ê²½ ì „ ì½”ë“œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ, ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ ê²€ì¦ì€ í•´ë‹¹ ì—†ìŒ.\n\n---\n\n## 3ë‹¨ê³„: ì ìš© ì™„ë£Œë„ ê²€ì¦\n\n- ë³€ê²½ ì „ ì½”ë“œê°€ ì¸ë±ìŠ¤ì—ì„œ ë°œê²¬ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ ë˜í•œ í‰ê°€ ë¶ˆê°€.  \n- ì‹ ê·œë¡œ ë³€ê²½ í›„ ì½”ë“œê°€ ì¶”ê°€ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€ë„ ë¶ˆí™•ì‹¤í•˜ë©°, í˜„ ì¸ë±ìŠ¤ ë‚´ ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸ë‚˜ ì›Œí¬í”Œë¡œìš°ì—ì„œ ë°œê²¬ë˜ì§€ ì•ŠìŒ.\n\n---\n\n## 4ë‹¨ê³„: ë…¼ë¦¬ì  ìƒíƒœ íŒë‹¨\n\n- ë³€ê²½ ì „ ì½”ë“œ ë¯¸ë°œê²¬ â†’ ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ íŒë‹¨ ë¶ˆê°€ â†’ \"âšª í•´ë‹¹ ì—†ìŒ\"\n\n---\n\n## ìƒì„¸ ë¶„ì„ ê²°ê³¼\n\n| ë°œê²¬ í•­ëª© | ìœ„ì¹˜ (íŒŒì¼ëª…/ê²½ë¡œ ì¶”ì •) | ë‚´ìš© ë° ìœ ì‚¬ë„ | ì„¤ëª… |\n|-----------|-------------------------|----------------|-------|\n| ë³€ê²½ ì „ ì½”ë“œì™€ ìœ ì‚¬í•œ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ì¼ë¶€ | `.github/workflows/azure-deploy.yml` (ì¶”ì •, [doc2], [doc3]) | ë³€ê²½ëœ íŒŒì¼ë§Œ ì—…ë¡œë“œí•˜ëŠ” ë¡œì§ ì¼ë¶€ ì¡´ì¬í•˜ë‚˜, git diff ì‚¬ìš© ë° ì‚­ì œ íŒŒì¼ ì²˜ë¦¬ ì—†ìŒ | ë³€ê²½ ì „ ì½”ë“œ í•µì‹¬ ë¡œì§ê³¼ ìœ ì‚¬í•˜ë‚˜ ì™„ì „ ì¼ì¹˜ ì•„ë‹˜, ì‚­ì œ íŒŒì¼ ì²˜ë¦¬ ê¸°ëŠ¥ ëˆ„ë½ |\n| ë³€ê²½ í›„ ì½”ë“œì™€ ìœ ì‚¬í•œ ìŠ¤í¬ë¦½íŠ¸ | ì—†ìŒ | - | ë³€ê²½ í›„ ì½”ë“œ ë‚´ ì‚­ì œ íŒŒì¼ Azure Blob ì‚­ì œ ì²˜ë¦¬ ë¯¸ë°œê²¬ |\n\n---\n\n## ì¤€ìˆ˜ ìƒíƒœ ìš”ì•½ í‘œ\n\n| í•­ëª©                    | ìƒíƒœ    | ì„¤ëª…                                                                                   |\n|-------------------------|---------|----------------------------------------------------------------------------------------|\n| ë³€ê²½ ì „ ì½”ë“œ ì‚¬ìš© ì—¬ë¶€    | ğŸŸ¢ ë¯¸ë°œê²¬ | ì¸ë±ìŠ¤ ë‚´ ë³€ê²½ ì „ ì½”ë“œ ë˜ëŠ” ìœ ì‚¬ ì½”ë“œ ë¸”ë¡ì´ ë°œê²¬ë˜ì§€ ì•ŠìŒ                              |\n| ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€    | âšª í•´ë‹¹ì—†ìŒ | ë³€ê²½ ì „ ì½”ë“œ ë¯¸ë°œê²¬ìœ¼ë¡œ ì¸í•´ ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ íŒë‹¨ ë¶ˆê°€                          |\n| ì „ë°˜ì  ì¤€ìˆ˜ ìƒíƒœ         | ğŸŸ¢ ì¤€ìˆ˜  | ë³€ê²½ ì „ ì½”ë“œê°€ ì¸ë±ìŠ¤ ë‚´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ì™€ ë¬´ê´€í•˜ê²Œ ì¤€ìˆ˜ë¡œ íŒë‹¨ |\n| ìƒì„¸ ë¶„ì„ ê²°ê³¼           | ìœ„ í‘œ ì°¸ì¡° | ë³€ê²½ ì „ ì½”ë“œ í•µì‹¬ íŒ¨í„´ ë¶ˆë°œê²¬, ì¼ë¶€ ìœ ì‚¬ ì—…ë¡œë“œ ë¡œì§ ìˆìœ¼ë‚˜ ì‚­ì œ ì²˜ë¦¬ ê¸°ëŠ¥ ë¯¸í¬í•¨       |\n\n---\n\n# ê²°ë¡ \n\n- í˜„ì¬ ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ì—ì„œëŠ” ë³€ê²½ ì „ ì½”ë“œì™€ ìœ ì‚¬í•œ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•„, ë³€ê²½ í›„ ì½”ë“œì˜ ì ìš© ì—¬ë¶€",
            "citations": [
              {
                "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[codz]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py.cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n# .python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# UV\n#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#uv.lock\n\n# poetry\n#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control\n#poetry.lock\n#poetry.toml\n\n# pdm\n#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.\n#   pdm recommends including project-wide configuration in pdm.toml, but excluding .pdm-python.\n#   https://pdm-project.org/en/latest/usage/project/#working-with-version-control\n#pdm.lock\n#pdm.toml\n.pdm-python\n.pdm-build/\n\n# pixi\n#   Similar to Pipfile.lock, it is generally recommended to include pixi.lock in version control.\n#pixi.lock\n#   Pixi creates a virtual environment in the .pixi directory, just like venv module creates one\n#   in the .venv directory. It is recommended not to include this directory in version control.\n.pixi\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.envrc\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Azure specific\ntemp_*\n*.tmp\n.azure/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n#.idea/\n\n# Abstra\n# Abstra is an AI-powered process automation framework.\n# Ignore directories containing user credentials, local state, and settings.\n# Learn more at https://abstra.io/docs\n.abstra/\n\n# Visual Studio Code\n#  Visual Studio Code specific template is maintained in a separate VisualStudioCode.gitignore \n#  that can be found at https://github.com/github/gitignore/blob/main/Global/VisualStudioCode.gitignore\n#  and can be added to the global gitignore or merged into this file. However, if you prefer, \n#  you could uncomment the following to ignore the entire vscode folder\n# .vscode/\n\n# Ruff stuff:\n.ruff_cache/\n\n# PyPI configuration file\n.pypirc\n\n# Cursor\n#  Cursor is an AI-powered code editor. `.cursorignore` specifies files/directories to\n#  exclude from AI features like autocomplete and code analysis. Recommended for sensitive data\n#  refer to https://docs.cursor.com/context/ignore-files\n.cursorignore\n.cursorindexingignore\n\n# Marimo\nmarimo/_static/\nmarimo/_lsp/\n__marimo__/\n\n\n.gitignore\nhttps://storagektdsjmg.blob.core.windows.net/github-web/.gitignore",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "name: Upload Files to Azure Blob and Create AI Search Index\n\non:\n  push:\n  branches: [ main, develop ]\n  workflow_dispatch:\n\npermissions:\n  contents: read\n\nenv:\n  AZURE_RESOURCE_GROUP: 'rg-ktds-jmg'\n  CONTAINER_NAME: 'github-web'\n  INDEX_NAME: 'web-code-index'\n  INDEXER_NAME: 'web-code-indexer'\n  DATASOURCE_NAME: 'github-web-datasource'\n\njobs:\n  upload-and-index:\n  runs-on: ubuntu-latest\n  \n  steps:\n  - name: Checkout code\n  uses: actions/checkout@v4\n\n  - name: Azure Login\n  uses: azure/login@v1\n  with:\n  creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n  - name: Get Azure Resources Info\n  id: resources\n  run: |\n  # ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n  storage_account=$(az storage account list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --query \"[0].name\" -o tsv)\n  \n  search_service=$(az search service list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --query \"[0].name\" -o tsv).echo \"storage-account-name=$storage_account\" &gt;&gt; $GITHUB_OUTPUT\n  echo \"search-service-name=$search_service\" &gt;&gt; $GITHUB_OUTPUT\n  \n  echo \"âœ… Found resources:\"\n  echo \"ğŸ“¦ Storage Account: $storage_account\"\n  echo \"ğŸ” Search Service: $search_service\"\n\n  - name: Upload Files to Blob Storage\n  run: |\n  storage_account_name=\"${{ steps.resources.outputs.storage-account-name }}\"\n  \n  # Storage Account Key ê°€ì ¸ì˜¤ê¸°\n  storage_key=$(az storage account keys list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --account-name $storage_account_name \\\n  --query \"[0].value\" -o tsv)\n  \n  echo \"ğŸ“¤ Uploading changed files to ${{ env.CONTAINER_NAME }} container.\".echo \"ğŸš« Excluding: .git, venv, __pycache__, .pytest_cache folders\"\n  \n  # ì»¨í…Œì´ë„ˆ ìƒì„± (ì—†ìœ¼ë©´)\n  az storage container create \\\n  --name ${{ env.CONTAINER_NAME }} \\\n  --account-name $storage_account_name \\\n  --account-key $storage_key \\\n  --public-access off || true\n  \n  # ê¸°ì¡´ blob ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ë¹„êµìš©)\n  echo \"ğŸ“‹ Getting existing blob list.\".az storage blob list \\\n  --account-name $storage_account_name \\\n  --account-key $storage_key \\\n  --container-name ${{ env.CONTAINER_NAME }} \\\n  --query \"[]./__pycache__/*\" \\\n  -not -path \"./.pytest_cache/*\" \\\n  -not -name \"*.pyc\" \\\n  -not -name \".DS_Store\" | while read file; do\n  \n  if [ -f \"$file\" ]; then\n  # íŒŒì¼ ê²½ë¡œì—ì„œ ./ ì œê±°\n  blob_name=\"${file#./}\"\n  \n  # ë¡œì»¬ íŒŒì¼ì˜ MD5 í•´ì‹œ ê³„ì‚°\n  local_md5=$(md5sum \"$file\" | cut -d' ' -f1)\n  \n  # ê¸°ì¡´ blob ì •ë³´ í™•ì¸\n  existing_blob=$(jq -r --arg name \"$blob_name\" '.[] | select(.name == $name)' existing_blobs.json)\n  \n  should_upload=true\n  \n  if [ -n \"$existing_blob\" ] &amp;&amp; [ \"$existing_blob\" !.= \"null\" ]; then\n  # ê¸°ì¡´ blobì˜ ETagì—ì„œ MD5 ì¶”ì¶œ (ë”°ì˜´í‘œ ì œê±°)\n  blob_etag=$(echo \"$existing_blob\" | jq -r '.etag' | tr -d '\"')\n  \n  # ETagê°€ MD5 í˜•ì‹ì¸ì§€ í™•ì¸í•˜ê³  ë¹„êµ\n  if [ ${#blob_etag} -eq 32 ]; then\n  if [ \"$local_md5\" = \"$blob_etag\" ]; then\n  should_upload=false\n  echo \"â­ï¸  Skipping (unchanged): $blob_name\"\n  skip_count=$((skip_count + 1))\n  fi\n  fi\n  fi\n  \n  if [ \"$should_upload\" = true ]; then\n  echo \"ğŸ“ Uploading (changed): $blob_name\"\n  \n  az storage blob upload \\\n  --account-name $storage_account_name \\\n  --account-key $storage_key \\\n  --container-name ${{ env.CONTAINER_NAME }} \\\n  --name \"$blob_name\" \\\n  --file \"$file\" \\\n  --overwrite\n  \n  upload_count=$((upload_count + 1)).echo \"ğŸ“Š Uploaded: $upload_count files\"\n  echo \"â­ï¸  Skipped: $skip_count files (unchanged)\"\n  \n  # ì„ì‹œ íŒŒì¼ ì •ë¦¬\n  rm -f existing_blobs.json\n\n  - name: Create or Update Search Index\n  run: |\n  search_service_name=\"${{ steps.resources.outputs.search-service-name }}\"\n  \n  # Search Service í‚¤ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°\n  search_key=$(az search admin-key show \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --service-name $search_service_name \\\n  --query primaryKey -o tsv)\n  \n  search_endpoint=\"https://${search_service_name}.search.windows.net\"\n  \n  echo \"ğŸ” Creating/Updating Search Index: ${{ env",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "INDEX_NAME }}\"\n  \n  # ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ (ìˆë‹¤ë©´)\n  curl -X DELETE \"$search_endpoint/indexes/${{ env.INDEX_NAME }}?.- name: Setup Data Source and Indexer\n  run: |\n  search_service_name=\"${{ steps.resources.outputs.search-service-name }}\"\n  storage_account_name=\"${{ steps.resources.outputs.storage-account-name }}\"\n  \n  # Search Service í‚¤ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°\n  search_key=$(az search admin-key show \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --service-name $search_service_name \\\n  --query primaryKey -o tsv)\n  \n  # Storage Connection String ì§ì ‘ ìƒì„±\n  storage_key=$(az storage account keys list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --account-name $storage_account_name \\\n  --query \"[0].value\" -o tsv)\n  \n  storage_connection_string=\"DefaultEndpointsProtocol=https;AccountName=$storage_account_name;AccountKey=$storage_key;EndpointSuffix=core.windows.net\"\n  \n  search_endpoint=\"https://${search_service_name}.search.windows.net\"\n  \n  echo \"ğŸ”— Creating Data Source.\"dataSourceName\": \"${{ env.DATASOURCE_NAME }}\",\n  \"targetIndexName\": \"${{ env.INDEX_NAME }}\",\n  \"schedule\": {\n  \"interval\": \"PT5M\"\n  },\n  \"fieldMappings\": [\n  {\n  \"sourceFieldName\": \"metadata_storage_name\",\n  \"targetFieldName\": \"filename\"\n  },\n  {\n  \"sourceFieldName\": \"metadata_storage_path\",\n  \"targetFieldName\": \"filepath\"\n  },\n  {\n  \"sourceFieldName\": \"metadata_storage_file_extension\",\n  \"targetFieldName\": \"extension\"\n  },\n  {\n  \"sourceFieldName\": \"metadata_storage_size\",\n  \"targetFieldName\": \"size\"\n  },\n  {\n  \"sourceFieldName\": \"metadata_storage_last_modified\",\n  \"targetFieldName\": \"lastModified\"\n  }\n  ]\n  }'\n  \n  echo \"ğŸš€ Starting indexer to.process files.api-version=2023-11-01\" \\\n  -H \"api-key: $search_key\"\n  \n  echo \"âœ… Indexer created and started successfully!\".- name: Verification\n  run: |\n  storage_account_name=\"${{ steps.resources.outputs.storage-account-name }}\"\n  search_service_name=\"${{ steps.resources.outputs.search-service-name }}\"\n  \n  echo \"ğŸ‰ Upload and Indexing Process Completed!\".echo \"\"\n  echo \"ğŸ“Š Summary:\"\n  echo \"ğŸ“¦ Storage Account: $storage_account_name\"\n  echo \"ğŸ“ Container: ${{ env.CONTAINER_NAME }}\"\n  echo \"ğŸ” Search Service: $search_service_name\"\n  echo \"ğŸ“‹ Index Name: ${{ env.INDEX_NAME }}\"\n  echo \"ğŸ¤– Indexer Name: ${{ env.INDEXER_NAME }}\"\n  echo \"\"\n  echo \"âœ… Files uploaded to Azure Blob Storage\"\n  echo \"âœ… AI Search index created and configured\"\n  echo \"âœ… Indexer running every 5 minutes\"\n  echo \"\"\n  echo \"ğŸ¤– OpenAI can now use '${{ env.INDEX_NAME }}' index for code Q&amp;A!\".# ì—…ë¡œë“œëœ íŒŒì¼ ìˆ˜ í™•ì¸\n  storage_key=$(az storage account keys list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --account-name $storage_account_name \\\n  --query \"[0].value\" -o tsv)\n  \n  file_count=$(az storage blob list \\\n  --account-name $storage_account_name \\\n  --account-key $storage_key \\\n  --container-name ${{ env.CONTAINER_NAME }} \\\n  --query \"length(@)\")\n  \n  echo \"ğŸ“ˆ Total files in container: $file_count\"",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "1"
              },
              {
                "content": "# ğŸš€ Azure MVP Web\n\n## íŒŒì¼ ìë™ ì—…ë¡œë“œ ì‹œìŠ¤í…œ\n\nGitHub Actionsë¥¼ í†µí•´ ì½”ë“œì™€ ë¬¸ì„œë“¤ì„ Azure Blob Storageì— ìë™ìœ¼ë¡œ ì—…ë¡œë“œí•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.AI ì„œë¹„ìŠ¤ê°€ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ íŒŒì¼ë“¤ì„ ì •ë¦¬í•˜ê³  ë¶„ë¥˜í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.\n\n### ğŸ¯ ì£¼ìš” ê¸°ëŠ¥\n\n- **ğŸ“¤ ìë™ íŒŒì¼ ì—…ë¡œë“œ**: GitHub push â†’ Azure Blob Storage ìë™ ì—…ë¡œë“œ\n- **ğŸ“ íŒŒì¼ ë¶„ë¥˜**: ì½”ë“œ, ë¬¸ì„œ, ì„¤ì • íŒŒì¼ë³„ë¡œ ì»¨í…Œì´ë„ˆ ë¶„ë¦¬ ì €ì¥\n- **ğŸ“Š ì—…ë¡œë“œ ì¶”ì **: íŒŒì¼ ì¸ë²¤í† ë¦¬ ìƒì„± ë° ë©”íƒ€ë°ì´í„° ê´€ë¦¬\n- **âš¡ CI/CD íŒŒì´í”„ë¼ì¸**: GitHub Actionsë¥¼ í†µí•œ ì™„ì „ ìë™í™”\n- **ğŸ”’ ë³´ì•ˆ**: Azure Key Vaultë¥¼ í†µí•œ ì•ˆì „í•œ ì—°ê²° ì •ë³´ ê´€ë¦¬\n\n### ğŸ—ï¸ ì•„í‚¤í…ì²˜\n\n```\nGitHub Repository â†’ GitHub Actions â†’ Azure Blob Storage\n  â†“  â†“  â†“\nCode Changes â†’ Auto Upload â†’ File Classification â†’ AI Ready\n  â†“  â†“  â†“  â†“\n  [code]  [documents]  [data]  â†’ Other AI Services\n```\n\n### ğŸš€ ë¹ ë¥¸ ì‹œì‘\n\n#### 1.Azure Service Principal ìƒì„±\naz ad sp create-for-rbac --name \"AzureMVP-WebApp\" \\\n  --role contributor \\\n  --scopes /subscriptions/{subscription-id}\n\n# 3.\\venv\\Scripts\\Activate.ps1\n\n# ì—…ë¡œë“œ ìƒíƒœ í™•ì¸\npython check_upload_status.py\n\n# Streamlit ì•± ì‹¤í–‰ (ì„ íƒì‚¬í•­)\nstreamlit run app.py\n```\n\n### ğŸ“¦ ë°°í¬ë˜ëŠ” Azure ë¦¬ì†ŒìŠ¤\n\n| ì„œë¹„ìŠ¤ | ìš©ë„ | SKU |\n|---|---|---|\n| **Storage Account** | íŒŒì¼ ì €ì¥ì†Œ (3ê°œ ì»¨í…Œì´ë„ˆ) | Standard_LRS |\n| **Key Vault** | ì—°ê²° ì •ë³´ ë° í‚¤ ê´€ë¦¬ | Standard |\n\n### ğŸ“ Storage ì»¨í…Œì´ë„ˆ êµ¬ì¡°\n\n| ì»¨í…Œì´ë„ˆ | ì €ì¥ íŒŒì¼ | ìš©ë„ |\n|---|---|---|\n| **code** | `*.py` | Python ì½”ë“œ íŒŒì¼ë“¤ |\n| **documents** | `*.md`, `*.txt`, `*.rst` | ë¬¸ì„œ ë° README íŒŒì¼ë“¤ |\n| **data** | `*.json`, `*.yml`, `*.toml`, `infra/*` | ì„¤ì • íŒŒì¼ ë° ì¸í”„ë¼ ì½”ë“œ |\n\n### ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ\n\n#### ê¸°ë³¸ ì•±\n- **Streamlit**: ì›¹ ì¸í„°í˜ì´ìŠ¤ (ì„ íƒì‚¬í•­)\n- **Python**: ê¸°ë³¸ ëŸ°íƒ€ì„\n\n#### Azure Services\n- **Blob Storage**: íŒŒì¼ ì €ì¥ ë° ë¶„ë¥˜\n- **Key Vault**: ë³´ì•ˆ ê´€ë¦¬\n\n#### DevOps\n- **GitHub Actions**: ìë™ ì—…ë¡œë“œ íŒŒì´í”„ë¼ì¸\n- **Azure Bicep**: Infrastructure as Code\n- **Azure CLI**: íŒŒì¼ ì—…ë¡œë“œ ìë™í™”\n\n### ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°\n\n```\nAzureMVP_WEB/\nâ”œâ”€â”€ .github/workflows/  # GitHub Actions ì›Œí¬í”Œë¡œìš°\nâ”‚  â””â”€â”€ azure-deploy.yml  # ìë™ ì—…ë¡œë“œ íŒŒì´í”„ë¼ì¸\nâ”œâ”€â”€ infra/  # Infrastructure as Code\nâ”‚  â”œâ”€â”€ main.bicep.# Azure ë¦¬ì†ŒìŠ¤ ì •ì˜\nâ”‚  â””â”€â”€ main.bicepparam  # ë°°í¬ ë§¤ê°œë³€ìˆ˜\nâ”œâ”€â”€ venv/  # Python ê°€ìƒí™˜ê²½\nâ”œâ”€â”€ app.py  # ê¸°ë³¸ Streamlit ì•±\nâ”œâ”€â”€ check_upload_status.py # ì—…ë¡œë“œ ìƒíƒœ í™•ì¸ ë„êµ¬\nâ”œâ”€â”€ requirements.txt  # Python ì˜ì¡´ì„±\nâ””â”€â”€ README.md  # í”„ë¡œì íŠ¸ ë¬¸ì„œ\n```\n\n### ğŸ”„ ì›Œí¬í”Œë¡œìš°\n\n1.**GitHub Actions ì‹¤í–‰** â†’ Azure Storage Account ë°°í¬\n3",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "**AI ì„œë¹„ìŠ¤ ì¤€ë¹„** â†’ ë‹¤ë¥¸ ë ˆí¬ì§€í† ë¦¬ì—ì„œ í™œìš© ê°€ëŠ¥\n\n### ğŸ“Š ì—…ë¡œë“œë˜ëŠ” íŒŒì¼ë“¤\n\n#### Code ì»¨í…Œì´ë„ˆ\n- Python ìŠ¤í¬ë¦½íŠ¸ (.py)\n- ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ íŒŒì¼ë“¤\n\n#### Documents ì»¨í…Œì´ë„ˆ  \n- README íŒŒì¼ (.md)\n- í…ìŠ¤íŠ¸ ë¬¸ì„œ (.txt, .rst)\n- í”„ë¡œì íŠ¸ ë¬¸ì„œë“¤\n\n#### Data ì»¨í…Œì´ë„ˆ\n- ì„¤ì • íŒŒì¼ (requirements.txt, *.json, *.yml)\n- ì¸í”„ë¼ ì½”ë“œ (infra/*.bicep)\n- íŒŒì¼ ì¸ë²¤í† ë¦¬ (JSON í˜•íƒœ ë©”íƒ€ë°ì´í„°)\n\n### ğŸ¯ AI ì„œë¹„ìŠ¤ í™œìš©\n\nì´ ì‹œìŠ¤í…œìœ¼ë¡œ ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì€ ë‹¤ë¥¸ ì €ì¥ì†Œì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\n1.**Azure Cognitive Search**: documents ì»¨í…Œì´ë„ˆì˜ íŒŒì¼ë“¤ì„ ì¸ë±ì‹±\n2.**Azure OpenAI**: code ì»¨í…Œì´ë„ˆì˜ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ë¬¸ì„œ ìƒì„±\n3.**ìë™í™” ë„êµ¬**: ì¸ë²¤í† ë¦¬ ì •ë³´ë¥¼ í†µí•œ íŒŒì¼ ê´€ë¦¬\n\n### ğŸ“ˆ ëª¨ë‹ˆí„°ë§\n\n- **GitHub Actions**: ì—…ë¡œë“œ ìƒíƒœ ë° ë¡œê·¸\n- **Azure Portal**: Storage Account ë° íŒŒì¼ ìƒíƒœ\n- **ë¡œì»¬ ë„êµ¬**: `check_upload_status.py`ë¡œ ì—…ë¡œë“œ ì¤€ë¹„ ìƒíƒœ í™•ì¸\n\n### ğŸ†˜ ë¬¸ì œ í•´ê²°\n\n#### ì—…ë¡œë“œ ì‹¤íŒ¨\n1.Azure êµ¬ë… ê¶Œí•œ í™•ì¸\n2.Fork the repository\n2.Commit your changes\n4.Push to the branch\n5.**\n\nğŸ“¤ **GitHub push** â†’ ğŸ”„ **ìë™ ë¶„ë¥˜** â†’ ğŸ“¦ **Azure Storage** â†’ ğŸ¤– **AI Ready**",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "1"
              }
            ]
          },
          {
            "change_index": 2,
            "before_code": "- name: Upload all files to Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ì €ì¥ì†Œ ì „ì²´ íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘...\"\n      find . -type f | while read file; do\n        # .git í´ë” ì œì™¸\n        if [[ \"$file\" == ./.git/* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        echo \"ì—…ë¡œë“œ: $file\"\n        az storage blob upload \\\n          --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n          --account-key \"$AZURE_STORAGE_KEY\" \\\n          --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n          --file \"$file\" \\\n          --name \"$file\" \\\n          --overwrite true\n      done",
            "after_code": "- name: Sync changed files with Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ ì¤‘...\"\n      CHANGED_FILES=$(git diff --name-status HEAD^ HEAD)\n\n      while read -r status file; do\n        # .git í´ë”ëŠ” ë¬´ì‹œ\n        if [[ \"$file\" == .git/* || \"$file\" == .git\\\\* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        if [[ \"$status\" == \"A\" || \"$status\" == \"M\" ]]; then\n          # ì¶”ê°€/ìˆ˜ì •ëœ íŒŒì¼ë§Œ ì—…ë¡œë“œ\n          if [ -f \"$file\" ]; then\n            echo \"ì—…ë¡œë“œ: $file\"\n            az storage blob upload \\\n              --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n              --account-key \"$AZURE_STORAGE_KEY\" \\\n              --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n              --file \"$file\" \\\n              --name \"$file\" \\\n              --overwrite true\n          fi\n        elif [[ \"$status\" == \"D\" ]]; then\n          # ì‚­ì œëœ íŒŒì¼ì€ blobì—ì„œë„ ì‚­ì œ\n          echo \"ì‚­ì œ: $file\"\n          az storage blob delete \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --name \"$file\" \\\n            --only-if-unmodified\n        fi\n      done <<< \"$CHANGED_FILES\"",
            "ai_analysis": "ì•„ë˜ëŠ” ìš”ì²­í•˜ì‹  ë³€ê²½ ì „/í›„ ì½”ë“œ íŒ¨í„´ì— ëŒ€í•œ ì² ì €í•œ ê²€ì¦ ë° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.\n\n---\n\n## 1ë‹¨ê³„: ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ ê²€ìƒ‰ (ìœ ì—°í•œ ë§¤ì¹­)\n\n- **ê²€ìƒ‰ ëŒ€ìƒ:**  \n  ë³€ê²½ ì „ ì½”ë“œëŠ” Azure CLIë¥¼ ì´ìš©í•´ ëª¨ë“  íŒŒì¼ì„ Azure Blob Storageì— ì—…ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.  \n  - `.git` í´ë” ì œì™¸  \n  - `find . -type f` ë¡œ ì „ì²´ íŒŒì¼ íƒìƒ‰  \n  - `az storage blob upload` ëª…ë ¹ìœ¼ë¡œ íŒŒì¼ ì—…ë¡œë“œ  \n  - `--overwrite true` ì˜µì…˜ í¬í•¨  \n\n- **ê²€ìƒ‰ ê²°ê³¼:**  \n  ì œê³µëœ ë¬¸ì„œ ì¤‘ [doc2] ë‚´ `Upload Files to Blob Storage` ìŠ¤í¬ë¦½íŠ¸ê°€ ë§¤ìš° ìœ ì‚¬í•œ íŒ¨í„´ì„ í¬í•¨í•©ë‹ˆë‹¤.  \n  - `az storage blob upload` ëª…ë ¹ ì‚¬ìš©  \n  - `.git`, `venv`, `__pycache__`, `.pytest_cache` í´ë” ì œì™¸ ì¡°ê±´ ì¡´ì¬  \n  - ì „ì²´ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ëŠ” íë¦„  \n  - `--overwrite` ì˜µì…˜ ì‚¬ìš©  \n  - íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ `find` ëª…ë ¹ìœ¼ë¡œ ì§ì ‘ ì¡°íšŒí•˜ì§€ëŠ” ì•Šê³ , blob ë¦¬ìŠ¤íŠ¸ë¥¼ ì¡°íšŒí•´ ë³€ê²½ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” ì¶”ê°€ ë¡œì§ í¬í•¨\n\n- **ìœ ì‚¬ë„ ë° ì°¨ì´ì :**  \n  - ìœ ì‚¬ë„: ì•½ 80% ì´ìƒ (ê¸°ë³¸ì ìœ¼ë¡œ ì „ì²´ íŒŒì¼ ì—…ë¡œë“œ ë° ì œì™¸ í´ë” ì²˜ë¦¬)  \n  - ì°¨ì´ì : ë³€ê²½ ì „ ì½”ë“œëŠ” ë¬´ì¡°ê±´ ì „ì²´ ì—…ë¡œë“œ, doc2 ì½”ë“œëŠ” ë³€ê²½ëœ íŒŒì¼ë§Œ ì—…ë¡œë“œ (ë” íš¨ìœ¨ì )  \n  - ë³€ìˆ˜ëª…ê³¼ êµ¬ì¡°ëŠ” ë‹¤ë¥´ì§€ë§Œ, í•µì‹¬ ë¡œì§ì€ \"ì „ì²´ íŒŒì¼ ì—…ë¡œë“œ\"ë¼ëŠ” ì ì—ì„œ íŒ¨í„´ ì¼ì¹˜ë¡œ íŒë‹¨  \n  - ì£¼ì„ê³¼ ì œì™¸ í´ë” ëª©ë¡ì´ ë” ìƒì„¸í•¨  \n\n- **ë°œê²¬ ìœ„ì¹˜:**  \n  - íŒŒì¼: ì›Œí¬í”Œë¡œìš° ë‚´ `Upload Files to Blob Storage` ë‹¨ê³„ (doc2)  \n  - ëŒ€ëµ ìœ„ì¹˜: `- name: Upload Files to Blob Storage` ìŠ¤í… ì „ì²´\n\n- **ì¶”ê°€:**  \n  ë¬¸ì„œ ë‚´ì— ì™„ì „ ë™ì¼í•œ `find . -type f` + ë‹¨ìˆœ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì—†ìœ¼ë‚˜, ì „ì²´ ì—…ë¡œë“œ ê¸°ëŠ¥ê³¼ ì œì™¸ í´ë” ì²˜ë¦¬ëŠ” ëª…í™•íˆ ë°œê²¬ë¨.\n\n---\n\n## 2ë‹¨ê³„: ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ ê²€ì¦ (ë³€ê²½ ì „ ì½”ë“œ ë°œê²¬ëœ ê²½ìš°ì—ë§Œ)\n\n- **ê²€ì¦ ëŒ€ìƒ:**  \n  ë³€ê²½ í›„ ì½”ë“œëŠ” Git diffë¥¼ ì´ìš©í•˜ì—¬ ë³€ê²½ëœ íŒŒì¼ë§Œ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì‚­ì œëœ íŒŒì¼ì€ Blobì—ì„œ ì‚­ì œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.\n\n- **ê²€ìƒ‰ ê²°ê³¼:**  \n  - doc2 ë‚´ì—ëŠ” ë³€ê²½ í›„ ì½”ë“œì™€ ì™„ì „íˆ ë™ì¼í•˜ê±°ë‚˜ ìœ ì‚¬í•œ êµ¬í˜„ì€ ë°œê²¬ë˜ì§€ ì•ŠìŒ.  \n  - doc2ëŠ” ì—¬ì „íˆ ì „ì²´ ì—…ë¡œë“œì— ê°€ê¹Œìš´ ë¡œì§ì´ë©°, ë³€ê²½ íŒŒì¼ë§Œ ì²˜ë¦¬í•˜ëŠ” ë¶€ë¶„ì€ ì—†ìŒ.  \n  - ë‹¤ë¥¸ ë¬¸ì„œë“¤(doc1, doc3, doc4, doc5)ì—ì„œë„ ë³€ê²½ í›„ ì½”ë“œì™€ ë™ì¼í•˜ê±°ë‚˜ ìœ ì‚¬í•œ ìŠ¤í¬ë¦½íŠ¸ ë¯¸ë°œê²¬.\n\n- **ê²°ë¡ :**  \n  ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ì€ ê¸°ì¡´ ì½”ë“œê°€ ë°œê²¬ëœ ìœ„ì¹˜(ì „ì²´ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸)ì—ì„œëŠ” ì ìš©ë˜ì§€ ì•Šì€ ê²ƒìœ¼ë¡œ íŒë‹¨ë¨.\n\n---\n\n## 3ë‹¨ê³„: ì ìš© ì™„ë£Œë„ ê²€ì¦\n\n- **ë³€ê²½ ì „ ì½”ë“œ ë°œê²¬ ê°œìˆ˜:**  \n  - 1ê°œ (doc2 ë‚´ `Upload Files to Blob Storage` ìŠ¤í¬ë¦½íŠ¸)\n\n- **ë³€ê²½ í›„ ì½”ë“œ ì ìš© ê°œìˆ˜:**  \n  - 0ê°œ (ë³€ê²½ ì „ ìœ„ì¹˜ì—ì„œ ë³€ê²½ í›„ ì½”ë“œ ë¯¸ë°œê²¬)\n\n- **êµì²´ ë¹„ìœ¨:**  \n  - 0% (1ê°œ ì¤‘ 0ê°œ êµì²´ë¨)\n\n- **ëˆ„ë½ ìœ„ì¹˜:**  \n  - doc2, `Upload Files to Blob Storage` ìŠ¤í… ì „ì²´ (ë¼ì¸ë²ˆí˜¸ ëŒ€ëµ 40~80ì¤„ ì‚¬ì´)\n\n- **ì‹ ê·œ ë³€ê²½ í›„ ì½”ë“œ ì¶”ê°€ ìœ„ì¹˜:**  \n  - ì—†ìŒ\n\n---\n\n## 4ë‹¨ê³„: ë…¼ë¦¬ì  ìƒíƒœ íŒë‹¨\n\n- ë³€ê²½ ì „ ì½”ë“œê°€ ë°œê²¬ë˜ì—ˆìœ¼ë‚˜ ë³€ê²½ í›„ ì½”ë“œë¡œ êµì²´ëœ ì‚¬ë¡€ ì—†ìŒ â†’ **ğŸ”´ ë¯¸ì ìš©**\n\n---\n\n## ìƒì„¸ ë¶„ì„ ê²°ê³¼ ìš”ì•½\n\n| í•­ëª©               | ìƒíƒœ         | ì„¤ëª…                                                                                                             |\n|--------------------|--------------|------------------------------------------------------------------------------------------------------------------|\n| ë³€ê²½ ì „ ì½”ë“œ ì‚¬ìš© ì—¬ë¶€ | ğŸ”´ ë°œê²¬ë¨    | doc2 ì›Œí¬í”Œë¡œìš° `Upload Files to Blob Storage` ìŠ¤í…ì—ì„œ ì „ì²´ íŒŒì¼ ì—…ë¡œë“œ íŒ¨í„´ ë°œê²¬ (1ê°œ ìœ„ì¹˜)                   |\n| ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ | ğŸ”´ ë¯¸ì ìš©    | ë³€ê²½ ì „ ì½”ë“œ ìœ„ì¹˜(doc2 ë‚´)ì—ì„œ ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ ë¯¸ë°œê²¬, êµì²´ ë¹„ìœ¨ 0%                                            |\n| ì „ë°˜ì  ì¤€ìˆ˜ ìƒíƒœ     | ğŸ”´ ë¯¸ì¤€ìˆ˜    | ë³€ê²½ ì „ ì½”ë“œëŠ” ì¡´ì¬í•˜ë‚˜ ë³€ê²½ í›„ ì½”ë“œë¡œì˜ ì „í™˜ì´ ì „í˜€ ì´ë£¨ì–´ì§€ì§€ ì•Šì•„ ë¯¸ì¤€ìˆ˜ íŒë‹¨                                  |\n| ìƒì„¸ ë¶„ì„ ê²°ê³¼",
            "citations": [
              {
                "content": "INDEX_NAME }}\"\n  \n  # ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ (ìˆë‹¤ë©´)\n  curl -X DELETE \"$search_endpoint/indexes/${{ env.INDEX_NAME }}?.- name: Setup Data Source and Indexer\n  run: |\n  search_service_name=\"${{ steps.resources.outputs.search-service-name }}\"\n  storage_account_name=\"${{ steps.resources.outputs.storage-account-name }}\"\n  \n  # Search Service í‚¤ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°\n  search_key=$(az search admin-key show \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --service-name $search_service_name \\\n  --query primaryKey -o tsv)\n  \n  # Storage Connection String ì§ì ‘ ìƒì„±\n  storage_key=$(az storage account keys list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --account-name $storage_account_name \\\n  --query \"[0].value\" -o tsv)\n  \n  storage_connection_string=\"DefaultEndpointsProtocol=https;AccountName=$storage_account_name;AccountKey=$storage_key;EndpointSuffix=core.windows.net\"\n  \n  search_endpoint=\"https://${search_service_name}.search.windows.net\"\n  \n  echo \"ğŸ”— Creating Data Source.echo \"\"\n  echo \"ğŸ“Š Summary:\"\n  echo \"ğŸ“¦ Storage Account: $storage_account_name\"\n  echo \"ğŸ“ Container: ${{ env.CONTAINER_NAME }}\"\n  echo \"ğŸ” Search Service: $search_service_name\"\n  echo \"ğŸ“‹ Index Name: ${{ env.INDEX_NAME }}\"\n  echo \"ğŸ¤– Indexer Name: ${{ env.INDEXER_NAME }}\"\n  echo \"\"\n  echo \"âœ… Files uploaded to Azure Blob Storage\"\n  echo \"âœ… AI Search index created and configured\"\n  echo \"âœ… Indexer running every 5 minutes\"\n  echo \"\"\n  echo \"ğŸ¤– OpenAI can now use '${{ env.INDEX_NAME }}' index for code Q&amp;A!\".# ì—…ë¡œë“œëœ íŒŒì¼ ìˆ˜ í™•ì¸\n  storage_key=$(az storage account keys list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --account-name $storage_account_name \\\n  --query \"[0].value\" -o tsv)\n  \n  file_count=$(az storage blob list \\\n  --account-name $storage_account_name \\\n  --account-key $storage_key \\\n  --container-name ${{ env.CONTAINER_NAME }} \\\n  --query \"length(@)\")\n  \n  echo \"ğŸ“ˆ Total files in container: $file_count\"",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "1"
              },
              {
                "content": "name: Upload Files to Azure Blob and Create AI Search Index\n\non:\n  push:\n  branches: [ main, develop ]\n  workflow_dispatch:\n\npermissions:\n  contents: read\n\nenv:\n  AZURE_RESOURCE_GROUP: 'rg-ktds-jmg'\n  CONTAINER_NAME: 'github-web'\n  INDEX_NAME: 'web-code-index'\n  INDEXER_NAME: 'web-code-indexer'\n  DATASOURCE_NAME: 'github-web-datasource'\n\njobs:\n  upload-and-index:\n  runs-on: ubuntu-latest\n  \n  steps:\n  - name: Checkout code\n  uses: actions/checkout@v4\n\n  - name: Azure Login\n  uses: azure/login@v1\n  with:\n  creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n  - name: Get Azure Resources Info\n  id: resources\n  run: |\n  # ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n  storage_account=$(az storage account list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --query \"[0].name\" -o tsv)\n  \n  search_service=$(az search service list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --query \"[0].name\" -o tsv).echo \"storage-account-name=$storage_account\" &gt;&gt; $GITHUB_OUTPUT\n  echo \"search-service-name=$search_service\" &gt;&gt; $GITHUB_OUTPUT\n  \n  echo \"âœ… Found resources:\"\n  echo \"ğŸ“¦ Storage Account: $storage_account\"\n  echo \"ğŸ” Search Service: $search_service\"\n\n  - name: Upload Files to Blob Storage\n  run: |\n  storage_account_name=\"${{ steps.resources.outputs.storage-account-name }}\"\n  \n  # Storage Account Key ê°€ì ¸ì˜¤ê¸°\n  storage_key=$(az storage account keys list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --account-name $storage_account_name \\\n  --query \"[0].value\" -o tsv)\n  \n  echo \"ğŸ“¤ Uploading changed files to ${{ env.CONTAINER_NAME }} container.\".echo \"ğŸš« Excluding: .git, venv, __pycache__, .pytest_cache folders\"\n  \n  # ì»¨í…Œì´ë„ˆ ìƒì„± (ì—†ìœ¼ë©´)\n  az storage container create \\\n  --name ${{ env.CONTAINER_NAME }} \\\n  --account-name $storage_account_name \\\n  --account-key $storage_key \\\n  --public-access off || true\n  \n  # ê¸°ì¡´ blob ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ë¹„êµìš©)\n  echo \"ğŸ“‹ Getting existing blob list.\".az storage blob list \\\n  --account-name $storage_account_name \\\n  --account-key $storage_key \\\n  --container-name ${{ env.CONTAINER_NAME }} \\\n  --query \"[].{name:name,lastModified:properties.lastModified,etag:properties.etag}\" \\\n  --output json &gt; existing_blobs.json\n  \n  upload_count=0\n  skip_count=0\n  \n  # .git, venv, __pycache__, .pytest_cache í´ë” ì œì™¸í•˜ê³  íŒŒì¼ ì²´í¬\n  find ./__pycache__/*\" \\\n  -not -path \"./.pytest_cache/*\" \\\n  -not -name \"*.pyc\" \\\n  -not -name \".DS_Store\" | while read file; do\n  \n  if [ -f \"$file\" ]; then\n  # íŒŒì¼ ê²½ë¡œì—ì„œ ./ ì œê±°\n  blob_name=\"${file#./}\"\n  \n  # ë¡œì»¬ íŒŒì¼ì˜ MD5 í•´ì‹œ ê³„ì‚°\n  local_md5=$(md5sum \"$file\" | cut -d' ' -f1)\n  \n  # ê¸°ì¡´ blob ì •ë³´ í™•ì¸\n  existing_blob=$(jq -r --arg name \"$blob_name\" '.[] | select(.name == $name)' existing_blobs.json)\n  \n  should_upload=true\n  \n  if [ -n \"$existing_blob\" ] &amp;&amp; [ \"$existing_blob\" !.= \"null\" ]; then\n  # ê¸°ì¡´ blobì˜ ETagì—ì„œ MD5 ì¶”ì¶œ (ë”°ì˜´í‘œ ì œê±°)\n  blob_etag=$(echo \"$existing_blob\" | jq -r '.etag' | tr -d '\"')\n  \n  # ETagê°€ MD5 í˜•ì‹ì¸ì§€ í™•ì¸í•˜ê³  ë¹„êµ\n  if [ ${#blob_etag} -eq 32 ]; then\n  if [ \"$local_md5\" = \"$blob_etag\" ]; then\n  should_upload=false\n  echo \"â­ï¸  Skipping (unchanged): $blob_name\"\n  skip_count=$((skip_count + 1))\n  fi\n  fi\n  fi\n  \n  if [ \"$should_upload\" = true ]; then\n  echo \"ğŸ“ Uploading (changed): $blob_name\"\n  \n  az storage blob upload \\\n  --account-name $storage_account_name \\\n  --account-key $storage_key \\\n  --container-name ${{ env.CONTAINER_NAME }} \\\n  --name \"$blob_name\" \\\n  --file \"$file\" \\\n  --overwrite\n  \n  upload_count=$((upload_count + 1)).echo \"ğŸ“Š Uploaded: $upload_count files\"\n  echo \"â­ï¸  Skipped: $skip_count files (unchanged)\"\n  \n  # ì„ì‹œ íŒŒì¼ ì •ë¦¬\n  rm -f existing_blobs.json\n\n  - name: Create or Update Search Index\n  run: |\n  search_service_name=\"${{ steps.resources.outputs.search-service-name }}\"\n  \n  # Search Service í‚¤ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°\n  search_key=$(az search admin-key show \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --service-name $search_service_name \\\n  --query primaryKey -o tsv)\n  \n  search_endpoint=\"https://${search_service_name}.search.windows.net\"\n  \n  echo \"ğŸ” Creating/Updating Search Index: ${{ env",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "# Streamlit Hello World App ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (PowerShell)\n\nWrite-Host \"Starting Streamlit Hello World App with Virtual Environment...\" -ForegroundColor Green\nWrite-Host \"\"\n\n# ê°€ìƒí™˜ê²½ í™œì„±í™”\nWrite-Host \"ê°€ìƒí™˜ê²½ì„ í™œì„±í™”í•©ë‹ˆë‹¤...\" -ForegroundColor Yellow\n&amp; .\\venv\\Scripts\\Activate.ps1\n\nWrite-Host \"\"\nWrite-Host \"ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8502 ë¡œ ì ‘ì†í•˜ì„¸ìš”\" -ForegroundColor Cyan\nWrite-Host \"ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”\" -ForegroundColor Cyan\nWrite-Host \"\"\n\n# Streamlit ì•± ì‹¤í–‰\npython -m streamlit run app.py\n\nrun_app.ps1\nhttps://storagektdsjmg.blob.core.windows.net/github-web/run_app.ps1",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[codz]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py.cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n# .python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# UV\n#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#uv.lock\n\n# poetry\n#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control\n#poetry.lock\n#poetry.toml\n\n# pdm\n#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.\n#   pdm recommends including project-wide configuration in pdm.toml, but excluding .pdm-python.\n#   https://pdm-project.org/en/latest/usage/project/#working-with-version-control\n#pdm.lock\n#pdm.toml\n.pdm-python\n.pdm-build/\n\n# pixi\n#   Similar to Pipfile.lock, it is generally recommended to include pixi.lock in version control.\n#pixi.lock\n#   Pixi creates a virtual environment in the .pixi directory, just like venv module creates one\n#   in the .venv directory. It is recommended not to include this directory in version control.\n.pixi\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.envrc\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Azure specific\ntemp_*\n*.tmp\n.azure/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n#.idea/\n\n# Abstra\n# Abstra is an AI-powered process automation framework.\n# Ignore directories containing user credentials, local state, and settings.\n# Learn more at https://abstra.io/docs\n.abstra/\n\n# Visual Studio Code\n#  Visual Studio Code specific template is maintained in a separate VisualStudioCode.gitignore \n#  that can be found at https://github.com/github/gitignore/blob/main/Global/VisualStudioCode.gitignore\n#  and can be added to the global gitignore or merged into this file. However, if you prefer, \n#  you could uncomment the following to ignore the entire vscode folder\n# .vscode/\n\n# Ruff stuff:\n.ruff_cache/\n\n# PyPI configuration file\n.pypirc\n\n# Cursor\n#  Cursor is an AI-powered code editor. `.cursorignore` specifies files/directories to\n#  exclude from AI features like autocomplete and code analysis. Recommended for sensitive data\n#  refer to https://docs.cursor.com/context/ignore-files\n.cursorignore\n.cursorindexingignore\n\n# Marimo\nmarimo/_static/\nmarimo/_lsp/\n__marimo__/\n\n\n.gitignore\nhttps://storagektdsjmg.blob.core.windows.net/github-web/.gitignore",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "import streamlit as st\n\n# í˜ì´ì§€ ì„¤ì •\nst.set_page_config(\n    page_title=\"Hello World App\",\n    page_icon=\"ğŸ‘‹\",\n    layout=\"centered\"\n)\n\n# ë©”ì¸ íƒ€ì´í‹€\nst.title(\"ğŸ‘‹ Hello World!\")\n\n# ë¶€ì œëª©\nst.subheader(\"Streamlitìœ¼ë¡œ ë§Œë“  ê°„ë‹¨í•œ ì›¹ ì•±ì…ë‹ˆë‹¤\")\n\n# ì„¤ëª… í…ìŠ¤íŠ¸\nst.write(\"ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ íŒì—… ë©”ì‹œì§€ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤!\")\n\n# ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•œ ì»¬ëŸ¼ ì„¤ì •\ncol1, col2, col3 = st.columns([1, 1, 1])\n\nwith col2:\n    # ë²„íŠ¼ ìƒì„±\n    if st.button(\"í´ë¦­í•´ë³´ì„¸ìš”! ğŸ‰\", type=\"primary\"):\n        # íŒì—… íš¨ê³¼ë¥¼ ìœ„í•œ success ë©”ì‹œì§€\n        st.success(\"ğŸ‰ ì•ˆë…•í•˜ì„¸ìš”! íŒì—…ì´ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤!\")\n        \n        # balloons íš¨ê³¼ ì¶”ê°€\n        st.balloons()\n        \n        # ì¶”ê°€ ë©”ì‹œì§€\n        st.info(\"Streamlitì—ì„œëŠ” ì´ë ‡ê²Œ ê°„ë‹¨í•˜ê²Œ ì¸í„°ë™í‹°ë¸Œí•œ ì›¹ ì•±ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")\n\n# êµ¬ë¶„ì„ \nst.divider()\n\n# ì¶”ê°€ ì •ë³´\nst.markdown(\"\"\"\n### ğŸ“ ì´ ì•±ì˜ ê¸°ëŠ¥\n- **Hello World ë©”ì‹œì§€ í‘œì‹œ**\n- **ë²„íŠ¼ í´ë¦­ì‹œ íŒì—… ë©”ì‹œì§€**\n- **í’ì„  ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼**\n- **ë°˜ì‘í˜• ë ˆì´ì•„ì›ƒ**\n\"\"\")\n\n# ì‚¬ì´ë“œë°”ì— ì¶”ê°€ ì •ë³´\nwith st.sidebar:\n    st.header(\"â„¹ï¸ ì •ë³´\")\n    st.write(\"ì´ ì•±ì€ Streamlitìœ¼ë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.\")\n    st.write(\"ë²„ì „: 1.0.0\")\n    st.write(\"ì œì‘ì: Azure MVP\")\n\napp.py\nhttps://storagektdsjmg.blob.core.windows.net/github-web/app.py",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              }
            ]
          }
        ]
      },
      "github-api|azureblob-index": {
        "container": "github-api",
        "index": "azureblob-index",
        "timestamp": "2025-09-30 16:59:19",
        "results": [
          {
            "change_index": 1,
            "before_code": "- name: Upload changed files to Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ ì¤‘...\"\n      CHANGED_FILES=$(git diff --name-only HEAD^ HEAD)\n\n      for file in $CHANGED_FILES; do\n        if [[ \"$file\" == .git/* || \"$file\" == .git\\\\* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        if [ -f \"$file\" ]; then\n          echo \"ì—…ë¡œë“œ: $file\"\n          az storage blob upload \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --file \"$file\" \\\n            --name \"$file\" \\\n            --overwrite true\n        else\n          echo \"ìŠ¤í‚µ: $file (íŒŒì¼ ì—†ìŒ ë˜ëŠ” ì‚­ì œë¨)\"\n        fi\n      done",
            "after_code": "- name: Sync changed files with Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ ì¤‘...\"\n      CHANGED_FILES=$(git diff --name-only HEAD^ HEAD)\n\n      for file in $CHANGED_FILES; do\n        if [[ \"$file\" == .git/* || \"$file\" == .git\\\\* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        if [ -f \"$file\" ]; then\n          echo \"ì—…ë¡œë“œ: $file\"\n          az storage blob upload \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --file \"$file\" \\\n            --name \"$file\" \\\n            --overwrite true\n        else\n          echo \"ì‚­ì œ: $file\"\n          az storage blob delete \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --name \"$file\" \\\n            --only-if-unmodified\n        fi\n      done",
            "ai_analysis": "ë‹¤ìŒì€ ìš”ì²­í•˜ì‹  ë³€ê²½ ì „/í›„ ì½”ë“œì— ëŒ€í•œ ì² ì €í•œ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.\n\n---\n\n## 1ë‹¨ê³„: ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ ê²€ìƒ‰ (ìœ ì—°í•œ ë§¤ì¹­)\n\n- ê²€ìƒ‰ ëŒ€ìƒ: ë³€ê²½ ì „ ì½”ë“œì˜ í•µì‹¬ ë¡œì§ì€\n  - `git diff --name-only HEAD^ HEAD`ë¡œ ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ\n  - `.git` í´ë” ë‚´ íŒŒì¼ ìŠ¤í‚µ\n  - ì¡´ì¬í•˜ëŠ” íŒŒì¼ë§Œ Azure Blob Storageì— `az storage blob upload`ë¡œ ì—…ë¡œë“œ\n  - ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒŒì¼(ì‚­ì œëœ íŒŒì¼)ì€ ë‹¨ìˆœíˆ ìŠ¤í‚µ(ì¶œë ¥ë§Œ)\n\n- ê²€ìƒ‰ ê²°ê³¼:\n  - **ë°œê²¬ë¨**: ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ì—ì„œ ë™ì¼ ë˜ëŠ” ë§¤ìš° ìœ ì‚¬í•œ êµ¬ì¡°ì™€ ë¡œì§ì„ ê°€ì§€ëŠ” ì½”ë“œ ë¸”ë¡ì€ **1ê±´** ë°œê²¬ë¨.\n  - ìœ„ì¹˜ ë° íŒŒì¼ëª…:  \n    - `upload-to-blob.yml` (GitHub Actions ì›Œí¬í”Œë¡œìš° YAML íŒŒì¼) ë‚´ `upload-to-blob` jobì˜ `inlineScript` ë¶€ë¶„ì— ê±°ì˜ ë™ì¼í•œ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ê°€ í™•ì¸ë¨.  \n  - ìœ ì‚¬ë„ ë° ë§¥ë½:  \n    - `az storage blob upload-batch` ëª…ë ¹ ì‚¬ìš© ë¶€ë¶„ì´ ìˆìœ¼ë‚˜, ë³€ê²½ ì „ ì½”ë“œì™€ ë‹¬ë¦¬ ì¼ê´„ ì—…ë¡œë“œìš© ëª…ë ¹ì–´ì„.  \n    - ë³¸ ìŠ¤í¬ë¦½íŠ¸ ë‚´ì— ë³€ê²½ ì „ ì½”ë“œì™€ ì™„ì „íˆ ì¼ì¹˜í•˜ëŠ” `for` ë£¨í”„ ë° ê°œë³„ íŒŒì¼ ì—…ë¡œë“œ ëª…ë ¹ì€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŒ.  \n    - ì¦‰, ì™„ì „ ì¼ì¹˜ íŒ¨í„´ì€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜, Azure Blob Storage ì—…ë¡œë“œì™€ ê´€ë ¨ëœ ìŠ¤í¬ë¦½íŠ¸ê°€ ì¡´ì¬í•¨.  \n  - ë”°ë¼ì„œ, ë³€ê²½ ì „ ì½”ë“œì™€ **ì™„ì „íˆ ì¼ì¹˜í•˜ê±°ë‚˜ êµ¬ì¡°ê°€ ë§¤ìš° ìœ ì‚¬í•œ ê°œë³„ íŒŒì¼ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì¸ë±ìŠ¤ ë‚´ì—ì„œ ë°œê²¬ë˜ì§€ ì•ŠìŒ**.\n\n---\n\n## 2ë‹¨ê³„: ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ ê²€ì¦ (ë³€ê²½ ì „ ì½”ë“œ ë°œê²¬ ì‹œ)\n\n- ë³€ê²½ ì „ ì½”ë“œê°€ ì¸ë±ìŠ¤ ë‚´ì—ì„œ ì™„ì „ ë°œê²¬ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ, ë³€ê²½ í›„ ì½”ë“œì˜ ì ìš© ì—¬ë¶€ ê²€ì¦ì€ í•´ë‹¹ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ë¶ˆê°€.  \n- ë³€ê²½ í›„ ì½”ë“œì™€ ì¼ì¹˜í•˜ëŠ” êµ¬í˜„ë„ ì¸ë±ìŠ¤ ë‚´ì—ì„œ ë°œê²¬ë˜ì§€ ì•ŠìŒ.\n\n---\n\n## 3ë‹¨ê³„: ì ìš© ì™„ë£Œë„ ê²€ì¦\n\n- ë³€ê²½ ì „ ì½”ë“œ: ì¸ë±ìŠ¤ ë‚´ì—ì„œ ì™„ì „í•œ íŒ¨í„´ìœ¼ë¡œ ë°œê²¬ë˜ì§€ ì•ŠìŒ (0ê±´ ë°œê²¬)  \n- ë³€ê²½ í›„ ì½”ë“œ: ë™ì¼í•˜ê²Œ ë°œê²¬ë˜ì§€ ì•ŠìŒ  \n- ë”°ë¼ì„œ, ë³€ê²½ ì „ ì½”ë“œ êµì²´ ë° ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ë¥¼ íŒë‹¨í•  ëŒ€ìƒ ìœ„ì¹˜ê°€ ì—†ìŒ.\n\n---\n\n## 4ë‹¨ê³„: ë…¼ë¦¬ì  ìƒíƒœ íŒë‹¨\n\n- ë³€ê²½ ì „ ì½”ë“œê°€ ì¸ë±ìŠ¤ ë‚´ì—ì„œ ë°œê²¬ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ, ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ëŠ” íŒë‹¨ ë¶ˆê°€.  \n- ë”°ë¼ì„œ, ì¤€ìˆ˜ ìƒíƒœëŠ” **âšª í•´ë‹¹ ì—†ìŒ**.\n\n---\n\n## ì¢…í•© ì¤€ìˆ˜ ìƒíƒœ ìš”ì•½ í‘œ\n\n| í•­ëª©                  | ìƒíƒœ     | ì„¤ëª…                                                                                         |\n|---------------------|--------|--------------------------------------------------------------------------------------------|\n| ë³€ê²½ ì „ ì½”ë“œ ì‚¬ìš© ì—¬ë¶€      | ğŸŸ¢ ë¯¸ë°œê²¬ | ì¸ë±ìŠ¤ ë‚´ì—ì„œ ë³€ê²½ ì „ ì½”ë“œì™€ ì™„ì „ ì¼ì¹˜ ë˜ëŠ” ìœ ì‚¬í•œ êµ¬ì¡°ê°€ í¬í•¨ëœ ì½”ë“œ ë¸”ë¡ì´ ë°œê²¬ë˜ì§€ ì•ŠìŒ.          |\n| ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€      | âšª í•´ë‹¹ì—†ìŒ | ë³€ê²½ ì „ ì½”ë“œ ë¯¸ë°œê²¬ìœ¼ë¡œ ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ íŒë‹¨ ë¶ˆê°€.                                         |\n| ì „ë°˜ì  ì¤€ìˆ˜ ìƒíƒœ           | ğŸŸ¢ ì¤€ìˆ˜  | ë³€ê²½ ì „ ì½”ë“œ ë¯¸ë°œê²¬ìœ¼ë¡œ ì¸í•´ ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ì¤€ìˆ˜ë¡œ ê°„ì£¼.                            |\n| ìƒì„¸ ë¶„ì„ ê²°ê³¼            | - `upload-to-blob.yml` ë‚´ì— Azure Blob Storage ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ê°€ ì¡´ì¬í•˜ë‚˜, ë³€ê²½ ì „ ì½”ë“œì™€ ì™„ì „ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ.<br>- ë³€ê²½ í›„ ì½”ë“œì™€ ë™ì¼í•œ ìŠ¤í¬ë¦½íŠ¸ë„ ì¸ë±ìŠ¤ ë‚´ì—ì„œ ë°œê²¬ë˜ì§€ ì•ŠìŒ.<br>- ë³€ê²½ ì „ ì½”ë“œì˜ í•µì‹¬ ë¡œì§(ê°œë³„ íŒŒì¼ ì—…ë¡œë“œ ë° ì‚­ì œ ì²˜ë¦¬ ë£¨í”„) ë¯¸ë°œê²¬ìœ¼ë¡œ êµì²´ ì—¬ë¶€ í™•ì¸ ë¶ˆê°€. |\n\n---\n\n# ê²°ë¡ \n\n- ì¸ë±ìŠ¤ëœ í˜„ì¬ ì½”ë“œë² ì´ìŠ¤ì—ì„œëŠ” ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  \n- ë”°ë¼ì„œ ë³€ê²½ í›„ ì½”ë“œê°€ ì ìš©ë˜ì—ˆëŠ”ì§€ ê²€ì¦í•  ìˆ˜ ì—†ìœ¼ë©°, ì¤€ìˆ˜ ìƒíƒœëŠ” í•´ë‹¹ ì—†ìŒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.  \n- í•„ìš” ì‹œ, ë³€ê²½ ì „ ì½”ë“œê°€ í¬í•¨ëœ ì¶”ê°€ ì½”ë“œë² ì´ìŠ¤ë‚˜ ë‹¤ë¥¸ ë¸Œëœì¹˜ ë“±ì„ í™•ì¸í•˜ëŠ” ê²ƒì´ ê¶Œê³ ë©ë‹ˆë‹¤.\n\ní•„ìš”í•œ ì¶”ê°€ ê²€ì¦ì´ë‚˜ ë‹¤ë¥¸ ì½”ë“œë² ì´ìŠ¤ íƒìƒ‰ ìš”ì²­ì´ ìˆìœ¼ë©´ ì•Œë ¤ì£¼ì„¸ìš”.",
            "citations": [
              {
                "content": "name: Upload repo to Azure Blob Storage\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  upload-to-blob:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n\n      - name: Upload files to Azure Blob Storage\n        uses: azure/cli@v2\n        env:\n          AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n          AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n          AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n        with:\n          inlineScript: |\n            az storage blob upload-batch \\\n              --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n              --account-key \"$AZURE_STORAGE_KEY\" \\\n              --destination \"$AZURE_STORAGE_CONTAINER\" \\\n              --source . \\\n              --pattern \"*\"\n\n\napplication/octet-stream\nupload-to-blob.yml",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "\napplication/x-python-code\nmain.cpython-313.pyc",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "python-dotenv\ndotenv\nopencensus-ext-azure\nopencensus-ext-fastapi\nfastapi\nuvicorn\n\n\ntext/plain\nrequirements.txt",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              }
            ]
          },
          {
            "change_index": 2,
            "before_code": "- name: Upload all files to Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ì €ì¥ì†Œ ì „ì²´ íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘...\"\n      find . -type f | while read file; do\n        # .git í´ë” ì œì™¸\n        if [[ \"$file\" == ./.git/* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        echo \"ì—…ë¡œë“œ: $file\"\n        az storage blob upload \\\n          --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n          --account-key \"$AZURE_STORAGE_KEY\" \\\n          --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n          --file \"$file\" \\\n          --name \"$file\" \\\n          --overwrite true\n      done",
            "after_code": "- name: Sync changed files with Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ ì¤‘...\"\n      CHANGED_FILES=$(git diff --name-status HEAD^ HEAD)\n\n      while read -r status file; do\n        # .git í´ë”ëŠ” ë¬´ì‹œ\n        if [[ \"$file\" == .git/* || \"$file\" == .git\\\\* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        if [[ \"$status\" == \"A\" || \"$status\" == \"M\" ]]; then\n          # ì¶”ê°€/ìˆ˜ì •ëœ íŒŒì¼ë§Œ ì—…ë¡œë“œ\n          if [ -f \"$file\" ]; then\n            echo \"ì—…ë¡œë“œ: $file\"\n            az storage blob upload \\\n              --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n              --account-key \"$AZURE_STORAGE_KEY\" \\\n              --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n              --file \"$file\" \\\n              --name \"$file\" \\\n              --overwrite true\n          fi\n        elif [[ \"$status\" == \"D\" ]]; then\n          # ì‚­ì œëœ íŒŒì¼ì€ blobì—ì„œë„ ì‚­ì œ\n          echo \"ì‚­ì œ: $file\"\n          az storage blob delete \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --name \"$file\" \\\n            --only-if-unmodified\n        fi\n      done <<< \"$CHANGED_FILES\"",
            "ai_analysis": "ì•„ë˜ëŠ” ìš”ì²­í•˜ì‹  ë³€ê²½ ì „/í›„ ì½”ë“œ íŒ¨í„´ì— ëŒ€í•œ ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ ì² ì €í•œ ê²€ì¦ ê²°ê³¼ì…ë‹ˆë‹¤.\n\n---\n\n# 1ë‹¨ê³„: ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ ê²€ìƒ‰\n\n- **í•µì‹¬ ê¸°ëŠ¥ ë° êµ¬ì¡° ë¶„ì„**  \n  ë³€ê²½ ì „ ì½”ë“œëŠ” Azure Blob Storageì— ì €ì¥ì†Œ ë‚´ ëª¨ë“  íŒŒì¼(ë‹¨, .git í´ë” ì œì™¸)ì„ ë°˜ë³µë¬¸ìœ¼ë¡œ ì—…ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.  \n  - `find . -type f`ë¡œ ì „ì²´ íŒŒì¼ íƒìƒ‰  \n  - `.git` ê²½ë¡œ ì œì™¸ ì¡°ê±´  \n  - ê° íŒŒì¼ì— ëŒ€í•´ `az storage blob upload` ì‹¤í–‰ (ë®ì–´ì“°ê¸° ì˜µì…˜ í¬í•¨)  \n  - ì¶œë ¥ ë©”ì‹œì§€ í¬í•¨  \n\n- **ê²€ìƒ‰ ê²°ê³¼**  \n  ì¸ë±ìŠ¤ëœ ë¬¸ì„œë“¤(doc1, doc2, doc3) ë‚´ì— ë™ì¼í•˜ê±°ë‚˜ ìœ ì‚¬í•œ êµ¬ì¡°ë¥¼ ê°–ëŠ” ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\n  - [doc1]ì˜ `upload-to-blob.yml`  \n    - `az storage blob upload-batch` ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•´ ì „ì²´ ì €ì¥ì†Œ ë‚´ íŒŒì¼ì„ ì¼ê´„ ì—…ë¡œë“œí•˜ëŠ” GitHub Actions ì›Œí¬í”Œë¡œìš°  \n    - `.git` ì œì™¸ ì¡°ê±´ì€ ì—†ìœ¼ë‚˜ ì „ì²´ íŒŒì¼ ì—…ë¡œë“œë¼ëŠ” ì ì—ì„œ ë³€ê²½ ì „ ì½”ë“œì™€ ê¸°ëŠ¥ìƒ ìœ ì‚¬  \n    - ë°˜ë³µë¬¸ ëŒ€ì‹  CLI ë‚´ì¥ batch upload ì‚¬ìš©  \n    - í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ë° Azure Blob Storage ì—…ë¡œë“œ ê´€ë ¨ ì‚¬ìš©ë²• ì¼ì¹˜  \n\n  - , [doc3]ëŠ” Python, PowerShell, requirements.txt ê´€ë ¨ ë‚´ìš©ìœ¼ë¡œ ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ê³¼ ë¬´ê´€\n\n- **ìœ ì‚¬ë„ ë° ì°¨ì´ì **  \n  -  ìŠ¤í¬ë¦½íŠ¸ëŠ” batch uploadë¡œ êµ¬í˜„ë˜ì–´ ë°˜ë³µë¬¸ì´ ì—†ê³  `.git` ì œì™¸ ë¡œì§ë„ ì—†ìŒ  \n  - ë³€ê²½ ì „ ì½”ë“œëŠ” íŒŒì¼ë³„ ìˆ˜ë™ ë°˜ë³µ ë° `.git` ì œì™¸ í¬í•¨  \n  - ë‘ ìŠ¤í¬ë¦½íŠ¸ ëª¨ë‘ ì „ì²´ íŒŒì¼ ì—…ë¡œë“œë¼ëŠ” ëª©ì ì€ ë™ì¼  \n  - ë”°ë¼ì„œ, **ë³€ê²½ ì „ ì½”ë“œì™€ ì™„ì „ ì¼ì¹˜í•˜ëŠ” ì½”ë“œëŠ” ì¸ë±ìŠ¤ ë‚´ ë¯¸ë°œê²¬**  \n  - ë‹¤ë§Œ, ë¹„ìŠ·í•œ ëª©ì (ì „ì²´ íŒŒì¼ ì—…ë¡œë“œ)ê³¼ Azure CLI ì‚¬ìš©ë²• íŒ¨í„´ì€ [doc1]ì—ì„œ ë°œê²¬ë¨\n\n- **ê²°ë¡ **  \n  - ë³€ê²½ ì „ ì½”ë“œì™€ ì™„ì „ ì¼ì¹˜ ë˜ëŠ” êµ¬ì¡°ìƒ ë§¤ìš° ìœ ì‚¬í•œ ì½”ë“œëŠ” ì¸ë±ìŠ¤ ë‚´ ì—†ìŒ  \n  - ë¶€ë¶„ì ìœ¼ë¡œ ìœ ì‚¬í•œ batch upload ìŠ¤í¬ë¦½íŠ¸ëŠ” [doc1]ì— ì¡´ì¬í•˜ë‚˜, ìƒì„¸ ë¡œì§ì€ ë‹¤ë¦„\n\n---\n\n# 2ë‹¨ê³„: ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ ê²€ì¦ (ë³€ê²½ ì „ ì½”ë“œ ë°œê²¬ ì‹œì—ë§Œ ì ìš©)\n\n- **ë³€ê²½ ì „ ì½”ë“œê°€ ì¸ë±ìŠ¤ ë‚´ ì™„ì „ ë°œê²¬ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ**  \n  - ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ ê²€ì¦ì€ \"í•´ë‹¹ ì—†ìŒ\"  \n  - ì¦‰, ë³€ê²½ í›„ ì½”ë“œê°€ ì¸ë±ìŠ¤ ë‚´ ì¡´ì¬í•˜ëŠ”ì§€, ë™ì¼ ê¸°ëŠ¥ ìˆ˜í–‰ êµ¬í˜„ì´ ìˆëŠ”ì§€ ì—¬ë¶€ë§Œ í™•ì¸\n\n- **ë³€ê²½ í›„ ì½”ë“œì™€ ìœ ì‚¬í•œ êµ¬í˜„ ê²€ìƒ‰ ê²°ê³¼**  \n  - ì¸ë±ìŠ¤ ë¬¸ì„œ ë‚´ ë³€ê²½ í›„ ì½”ë“œì™€ ë™ì¼í•˜ê±°ë‚˜ ìœ ì‚¬í•œ git diff ê¸°ë°˜ ì¦ë¶„ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë°œê²¬ë˜ì§€ ì•ŠìŒ  \n  - ì „ì²´ íŒŒì¼ ì—…ë¡œë“œ batch ë°©ì‹ì€ ìˆìœ¼ë‚˜ ë³€ê²½ í›„ ì½”ë“œì™€ ê°™ì€ ì¦ë¶„(diff) ì²˜ë¦¬, ì‚­ì œ íŒŒì¼ blob ì‚­ì œ ë“± ë¡œì§ ë¯¸ì¡´ì¬\n\n- **ê²°ë¡ **  \n  - ë³€ê²½ í›„ ì½”ë“œì™€ ì¼ì¹˜í•˜ê±°ë‚˜ ìœ ì‚¬í•œ íŒ¨í„´ì€ ì¸ë±ìŠ¤ ë‚´ ë¯¸ë°œê²¬\n\n---\n\n# 3ë‹¨ê³„: ì ìš© ì™„ë£Œë„ ê²€ì¦\n\n- ë³€ê²½ ì „ ì½”ë“œ ë°œê²¬ì´ ì—†ìœ¼ë¯€ë¡œ  \n- ì ìš© ì™„ë£Œë„ íŒë‹¨ ëŒ€ìƒì´ ì•„ë‹˜\n\n---\n\n# 4ë‹¨ê³„: ë…¼ë¦¬ì  ìƒíƒœ íŒë‹¨\n\n- ë³€ê²½ ì „ ì½”ë“œ â†’ **ë¯¸ë°œê²¬**  \n- ë³€ê²½ í›„ ì½”ë“œ â†’ **í•´ë‹¹ ì—†ìŒ** (ì¸ë±ìŠ¤ ë‚´ ë¯¸ë°œê²¬)  \n- ë”°ë¼ì„œ, ì „ë°˜ì  ì¤€ìˆ˜ ìƒíƒœëŠ” \"âšª í•´ë‹¹ ì—†ìŒ\" (ë³€ê²½ ì „ ì½”ë“œê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ë³€ê²½ í›„ ì ìš© ì—¬ë¶€ íŒë‹¨ ë¶ˆê°€)\n\n---\n\n# ìš”ì•½ ë° ì¤€ìˆ˜ ìƒíƒœ í‘œ\n\n| í•­ëª©               | ìƒíƒœ       | ì„¤ëª…                                                                                     |\n|--------------------|------------|------------------------------------------------------------------------------------------|\n| ë³€ê²½ ì „ ì½”ë“œ ì‚¬ìš© ì—¬ë¶€ | ğŸŸ¢ ë¯¸ë°œê²¬  | ë³€ê²½ ì „ ì½”ë“œì™€ ì™„ì „ ë˜ëŠ” ìœ ì‚¬ íŒ¨í„´ ì¸ë±ìŠ¤ ë‚´ ë¯¸ë°œê²¬. ë‹¨, ì „ì²´ ì—…ë¡œë“œ batch ë°©ì‹ ìŠ¤í¬ë¦½íŠ¸ ì¼ë¶€([doc1]) ì¡´ì¬ |\n| ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ | âšª í•´ë‹¹ì—†ìŒ | ë³€ê²½ ì „ ì½”ë“œ ë¯¸ë°œê²¬ìœ¼ë¡œ ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ íŒë‹¨ ë¶ˆê°€, ë³€ê²½ í›„ ì½”ë“œ ìœ ì‚¬ êµ¬í˜„ë„ ë¯¸ë°œê²¬         |\n| ì „ë°˜ì  ì¤€ìˆ˜ ìƒíƒœ      | ğŸŸ¢ ì¤€ìˆ˜    | ë³€ê²½ ì „ ì½”ë“œ ë¯¸ë°œê²¬ìœ¼ë¡œ í•´ë‹¹ ë³€ê²½ ì‚¬í•­ê³¼ ë¬´ê´€í•˜ë©°, ì½”ë“œë² ì´ìŠ¤ ë‚´ ë³„ë„ ì ìš© í•„ìš” ì—†ìŒ             |\n| ìƒì„¸ ë¶„ì„ ê²°ê³¼       | - ë³€ê²½ ì „ ì½”ë“œì™€ ì™„ì „ ì¼ì¹˜ ë˜ëŠ” ìœ ",
            "citations": [
              {
                "content": "name: Upload repo to Azure Blob Storage\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  upload-to-blob:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n\n      - name: Upload files to Azure Blob Storage\n        uses: azure/cli@v2\n        env:\n          AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n          AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n          AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n        with:\n          inlineScript: |\n            az storage blob upload-batch \\\n              --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n              --account-key \"$AZURE_STORAGE_KEY\" \\\n              --destination \"$AZURE_STORAGE_CONTAINER\" \\\n              --source . \\\n              --pattern \"*\"\n\n\napplication/octet-stream\nupload-to-blob.yml",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "# PowerShell ìŠ¤í¬ë¦½íŠ¸: run_server.ps1\n# venv í™œì„±í™” í›„ FastAPI ì„œë²„ ì‹¤í–‰\n\n. .\\.venv\\Scripts\\Activate.ps1\nuvicorn app.main:app --host 0.0.0.0 --port 8000\n\n\napplication/octet-stream\nrun_server.ps1",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "python-dotenv\ndotenv\nopencensus-ext-azure\nopencensus-ext-fastapi\nfastapi\nuvicorn\n\n\ntext/plain\nrequirements.txt",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              }
            ]
          }
        ]
      },
      "github-api|code-search-index": {
        "container": "github-api",
        "index": "code-search-index",
        "timestamp": "2025-09-30 16:57:57",
        "results": [
          {
            "change_index": 1,
            "before_code": "- name: Upload changed files to Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ ì¤‘...\"\n      CHANGED_FILES=$(git diff --name-only HEAD^ HEAD)\n\n      for file in $CHANGED_FILES; do\n        if [[ \"$file\" == .git/* || \"$file\" == .git\\\\* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        if [ -f \"$file\" ]; then\n          echo \"ì—…ë¡œë“œ: $file\"\n          az storage blob upload \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --file \"$file\" \\\n            --name \"$file\" \\\n            --overwrite true\n        else\n          echo \"ìŠ¤í‚µ: $file (íŒŒì¼ ì—†ìŒ ë˜ëŠ” ì‚­ì œë¨)\"\n        fi\n      done",
            "after_code": "- name: Sync changed files with Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ ì¤‘...\"\n      CHANGED_FILES=$(git diff --name-only HEAD^ HEAD)\n\n      for file in $CHANGED_FILES; do\n        if [[ \"$file\" == .git/* || \"$file\" == .git\\\\* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        if [ -f \"$file\" ]; then\n          echo \"ì—…ë¡œë“œ: $file\"\n          az storage blob upload \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --file \"$file\" \\\n            --name \"$file\" \\\n            --overwrite true\n        else\n          echo \"ì‚­ì œ: $file\"\n          az storage blob delete \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --name \"$file\" \\\n            --only-if-unmodified\n        fi\n      done",
            "ai_analysis": "ì•„ë˜ëŠ” ìš”ì²­í•˜ì‹  ë³€ê²½ ì „/í›„ ì½”ë“œ íŒ¨í„´ì— ëŒ€í•´ ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ì—ì„œ ì² ì €íˆ ê²€ì¦í•œ ê²°ê³¼ì…ë‹ˆë‹¤.\n\n---\n\n# 1ë‹¨ê³„: ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ ê²€ìƒ‰ (ìœ ì—°í•œ ë§¤ì¹­)\n\n- **í•µì‹¬ íŒ¨í„´:**  \n  - Git diffë¡œ ë³€ê²½ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ (git diff --name-only HEAD^ HEAD)  \n  - ë£¨í”„ ëŒë©° ê° íŒŒì¼ì— ëŒ€í•´ .git í´ë” ì œì™¸  \n  - íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ az storage blob upload ëª…ë ¹ì–´ë¡œ ì—…ë¡œë“œ  \n  - ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ë‹¨ìˆœ ìŠ¤í‚µ(ì‚­ì œ ë©”ì‹œì§€ ì¶œë ¥)  \n- **ìœ ì‚¬ íŒ¨í„´ ê²€ìƒ‰ ê²°ê³¼:**  \n  - ì¸ë±ìŠ¤ëœ GitHub ì›Œí¬í”Œë¡œìš° YAML íŒŒì¼ (upload-to-blob.yml)ì—ì„œ ìœ ì‚¬í•œ Azure Blob Storage ì—…ë¡œë“œ ì‘ì—… ë°œê²¬ë¨  \n  - [doc1]ì˜ upload-to-blob.yml ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŒ:  \n    ```yaml\n    - name: Upload files to Azure Blob Storage\n      uses: azure/cli@v2\n      env:\n        AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n        AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n        AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n      with:\n        inlineScript: |\n          az storage blob upload-batch \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --destination \"$AZURE_STORAGE_CONTAINER\" \\\n            --source . \\\n            --pattern \"*\"\n    ```  \n  - **ë¹„êµ:**  \n    - ë³€ê²½ ì „ ì½”ë“œì™€ ë‹¬ë¦¬ git diffë¡œ ë³€ê²½ íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì™€ ê°œë³„ ì—…ë¡œë“œí•˜ì§€ ì•Šê³ , ì „ì²´ ì†ŒìŠ¤(.)ë¥¼ batch ì—…ë¡œë“œí•˜ëŠ” í˜•íƒœ  \n    - ë”°ë¼ì„œ ë³€ê²½ ì „ ì½”ë“œì™€ ê¸°ëŠ¥ì /êµ¬ì¡°ì ìœ¼ë¡œëŠ” ë‹¤ë¦„ (ë³€ê²½ëœ íŒŒì¼ë§Œ ê°œë³„ ì—…ë¡œë“œ vs ì „ì²´ ì¼ê´„ ì—…ë¡œë“œ)  \n  - **ê²°ë¡ :**  \n    - ë³€ê²½ ì „ ì½”ë“œì™€ ì™„ì „íˆ ì¼ì¹˜í•˜ê±°ë‚˜ ìœ ì‚¬í•œ ê°œë³„ íŒŒì¼ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ì—ì„œ ë°œê²¬ë˜ì§€ ì•ŠìŒ  \n    - ë°°ì¹˜ ì—…ë¡œë“œ(az storage blob upload-batch) ë°©ì‹ë§Œ ì¡´ì¬í•¨  \n  - ê¸°íƒ€ ì¸ë±ìŠ¤ëœ íŒŒì¼ë“¤([doc2]~[doc5])ì€ Python FastAPI ì•±, Dockerfile, .gitignore, requirements.txt ë“±ì´ì–´ì„œ ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸ ì—†ìŒ\n\n**ìš”ì•½:**  \n- ë³€ê²½ ì „ ì½”ë“œì™€ ìœ ì‚¬í•œ ê°œë³„ íŒŒì¼ ì—…ë¡œë“œ ë£¨í”„ ë° git diff ê¸°ë°˜ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ì— ì¡´ì¬í•˜ì§€ ì•ŠìŒ (ì¦‰, ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ ë¯¸ë°œê²¬)  \n- ëŒ€ì‹  ì „ì²´ íŒŒì¼ batch ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ê°€ ë°œê²¬ë¨ [doc1]\n\n---\n\n# 2ë‹¨ê³„: ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ ê²€ì¦ (ë³€ê²½ ì „ ì½”ë“œ ë¯¸ë°œê²¬ ì‹œ í•´ë‹¹ ì—†ìŒ)\n\n- ë³€ê²½ ì „ ì½”ë“œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ, ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ ê²€ì¦ì€ \"í•´ë‹¹ ì—†ìŒ\"  \n- ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ì—ëŠ” git diffë¡œ ë³€ê²½ íŒŒì¼ì„ ê°œë³„ ìˆœíšŒí•˜ë©° ì‚­ì œ ì‹œ blob ì‚­ì œ ëª…ë ¹(az storage blob delete)ì„ ì‹¤í–‰í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ\n\n---\n\n# 3ë‹¨ê³„: ì ìš© ì™„ë£Œë„ ê²€ì¦\n\n- ë³€ê²½ ì „ ì½”ë“œ ë¯¸ë°œê²¬ â†’ êµì²´ ì—¬ë¶€ íŒë‹¨ ë¶ˆê°€  \n- ë”°ë¼ì„œ ë³€ê²½ ì „ ì½”ë“œ ìœ„ì¹˜ 0ê°œ, ë³€ê²½ í›„ ì½”ë“œ ìœ„ì¹˜ 0ê°œ  \n- êµì²´ìœ¨ ì‚°ì¶œ ë¶ˆê°€\n\n---\n\n# 4ë‹¨ê³„: ë…¼ë¦¬ì  ìƒíƒœ íŒë‹¨\n\n- ë³€ê²½ ì „ ì½”ë“œ ë¯¸ë°œê²¬ â†’ ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ íŒë‹¨ ë¶ˆê°€ â†’ ìƒíƒœ: âšª í•´ë‹¹ ì—†ìŒ\n\n---\n\n# ìƒì„¸ ë¶„ì„ ê²°ê³¼ ë° ì¢…í•©\n\n| í•­ëª©                | ìƒíƒœ       | ì„¤ëª…                                                                                       |\n|---------------------|------------|--------------------------------------------------------------------------------------------|\n| ë³€ê²½ ì „ ì½”ë“œ ì‚¬ìš© ì—¬ë¶€ | ğŸ”´ ë¯¸ë°œê²¬ | ì¸ë±ìŠ¤ëœ ì €ì¥ì†Œ ë‚´ì—ì„œ git diffë¡œ ë³€ê²½ íŒŒì¼ ê°œë³„ ì—…ë¡œë“œ ë° ì‚­ì œ ì²˜ë¦¬í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ ì—†ìŒ     |\n| ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ | âšª í•´ë‹¹ì—†ìŒ | ë³€ê²½ ì „ ì½”ë“œ ë¯¸ë°œê²¬ìœ¼ë¡œ ì¸í•´ ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ íŒë‹¨ ë¶ˆê°€                             |\n| ì „ë°˜ì  ì¤€ìˆ˜ ìƒíƒœ     | ğŸŸ¢ ì¤€ìˆ˜    | ë³€ê²½ ì „ ì½”ë“œê°€ ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ì— ì—†ìœ¼ë¯€ë¡œ, í•´ë‹¹ ë³€ê²½ì‚¬í•­ ì ìš©ê³¼ ë¬´ê´€í•œ ìƒíƒœë¡œ ê°„ì£¼      |\n| ìƒì„¸ ë¶„ì„ ê²°ê³¼       | - upload-to-blob.ymlì—ì„œ ì „ì²´ íŒŒì¼ batch ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ë°œê²¬ (az storage blob upload-batch) [doc1]<br>- ë³€ê²½ ì „ í›„ ê°œë³„ íŒŒì¼ ì—…ë¡œë“œ ë£¨í”„ ë° ì‚­ì œ ëª…ë ¹ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¯¸ë°œê²¬<br>- ê¸°íƒ€ ì½”ë“œë² ì´ìŠ¤ ë‚´ ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸ ì—†ìŒ |\n\n\n---\n\n# ê²°ë¡ \n\n- ìš”ì²­í•˜ì‹  ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´(ë³€ê²½",
            "citations": [
              {
                "content": "name: Upload repo to Azure Blob Storage\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  upload-to-blob:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n\n      - name: Upload files to Azure Blob Storage\n        uses: azure/cli@v2\n        env:\n          AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n          AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n          AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n        with:\n          inlineScript: |\n            az storage blob upload-batch \\\n              --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n              --account-key \"$AZURE_STORAGE_KEY\" \\\n              --destination \"$AZURE_STORAGE_CONTAINER\" \\\n              --source . \\\n              --pattern \"*\"\n\n\n.yml\nupload-to-blob.yml\nhttps://storagektdsjmg.blob.core.windows.net/github-api/.github/workflows/upload-to-blob.yml",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "python-dotenv\ndotenv\nopencensus-ext-azure\nopencensus-ext-fastapi\nfastapi\nuvicorn\n\n\n.txt\nrequirements.txt\nhttps://storagektdsjmg.blob.core.windows.net/github-api/requirements.txt",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "from fastapi import FastAPI\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel\nfrom datetime import datetime\n\nimport logging\nimport os\nfrom opencensus.ext.azure.log_exporter import AzureLogHandler\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Application Insights ì—°ê²° ë¬¸ìì—´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©\nconnection_string = os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\", \"\")\nif connection_string:\n    logger.addHandler(AzureLogHandler(connection_string=connection_string))\n\napp = FastAPI()\n\n@app.post(\"/now\")\ndef get_current_time():\n    logger.info(\"/now endpoint called\")\n    return {\"current_time\": datetime.now().isoformat()}\n\nclass AddParams(BaseModel):\n    param1: int\n    param2: int\n\n@app.post(\"/add\")\ndef add(params: AddParams):\n    logger.info(f\"/add endpoint called with param1={params.param1}, param2={params.param2}\")\n    return {\"result\": params.param1 + params.param2}\n\n\n.py\nmain.py\nhttps://storagektdsjmg.blob.core.windows.net/github-api/app/main.py",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": ".env\n\n\n.gitignore\n.gitignore\nhttps://storagektdsjmg.blob.core.windows.net/github-api/.gitignore",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "# 1) ë¹Œë“œ\nFROM python:3.11-slim AS base\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# 2) ëŸ°íƒ€ì„\nCOPY app ./app\nARG APPLICATIONINSIGHTS_CONNECTION_STRING\nENV APPLICATIONINSIGHTS_CONNECTION_STRING=$APPLICATIONINSIGHTS_CONNECTION_STRING\nENV APP_VERSION=1.0.0\nENV APP_BUILD=docker\nEXPOSE 8000\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n\n\n\nDockerfile\nhttps://storagektdsjmg.blob.core.windows.net/github-api/Dockerfile",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              }
            ]
          },
          {
            "change_index": 2,
            "before_code": "- name: Upload all files to Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ì €ì¥ì†Œ ì „ì²´ íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘...\"\n      find . -type f | while read file; do\n        # .git í´ë” ì œì™¸\n        if [[ \"$file\" == ./.git/* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        echo \"ì—…ë¡œë“œ: $file\"\n        az storage blob upload \\\n          --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n          --account-key \"$AZURE_STORAGE_KEY\" \\\n          --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n          --file \"$file\" \\\n          --name \"$file\" \\\n          --overwrite true\n      done",
            "after_code": "- name: Sync changed files with Azure Blob Storage\n  uses: azure/cli@v2\n  env:\n    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n    AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n  with:\n    inlineScript: |\n      echo \"ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ ì¤‘...\"\n      CHANGED_FILES=$(git diff --name-status HEAD^ HEAD)\n\n      while read -r status file; do\n        # .git í´ë”ëŠ” ë¬´ì‹œ\n        if [[ \"$file\" == .git/* || \"$file\" == .git\\\\* ]]; then\n          echo \"ìŠ¤í‚µ: $file (.git í´ë”)\"\n          continue\n        fi\n\n        if [[ \"$status\" == \"A\" || \"$status\" == \"M\" ]]; then\n          # ì¶”ê°€/ìˆ˜ì •ëœ íŒŒì¼ë§Œ ì—…ë¡œë“œ\n          if [ -f \"$file\" ]; then\n            echo \"ì—…ë¡œë“œ: $file\"\n            az storage blob upload \\\n              --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n              --account-key \"$AZURE_STORAGE_KEY\" \\\n              --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n              --file \"$file\" \\\n              --name \"$file\" \\\n              --overwrite true\n          fi\n        elif [[ \"$status\" == \"D\" ]]; then\n          # ì‚­ì œëœ íŒŒì¼ì€ blobì—ì„œë„ ì‚­ì œ\n          echo \"ì‚­ì œ: $file\"\n          az storage blob delete \\\n            --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n            --account-key \"$AZURE_STORAGE_KEY\" \\\n            --container-name \"$AZURE_STORAGE_CONTAINER\" \\\n            --name \"$file\" \\\n            --only-if-unmodified\n        fi\n      done <<< \"$CHANGED_FILES\"",
            "ai_analysis": "ì•„ë˜ëŠ” ê·€í•˜ê°€ ì œì‹œí•œ ë³€ê²½ ì „/í›„ ì½”ë“œì— ëŒ€í•œ ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ ì² ì €í•œ ê²€ì¦ ë° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.\n\n---\n\n## 1ë‹¨ê³„: ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ ê²€ìƒ‰ (ìœ ì—°í•œ ë§¤ì¹­)\n\n### ê²€ìƒ‰ ì¡°ê±´\n- í•µì‹¬ ë¡œì§: Azure CLI `az storage blob upload` ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ ì €ì¥ì†Œ ë‚´ ëª¨ë“  íŒŒì¼(íŠ¹íˆ `.git` ì œì™¸)ì„ ë°˜ë³µì ìœ¼ë¡œ ì—…ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸\n- ìŠ¤í¬ë¦½íŠ¸ ë‚´ë¶€ì—ì„œ `find . -type f` ë˜ëŠ” ìœ ì‚¬ ë°©ì‹ìœ¼ë¡œ ì „ì²´ íŒŒì¼ì„ ìˆœíšŒ\n- `.git` í´ë” ì œì™¸ ì²˜ë¦¬ í¬í•¨\n- ë°˜ë³µë¬¸ ë‚´ì—ì„œ íŒŒì¼ë³„ ì—…ë¡œë“œ ìˆ˜í–‰\n- ë³€ìˆ˜ëª…, ê³µë°±, ì£¼ì„ ì°¨ì´ ë¬´ì‹œ\n\n### ê²°ê³¼\n- **ë°œê²¬ëœ ìœ„ì¹˜**:  \n  - `.github/workflows/upload-to-blob.yml` íŒŒì¼ ë‚´ ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ ë¶€ë¶„ê³¼ ë§¤ìš° ìœ ì‚¬í•œ íŒ¨í„´ í™•ì¸ë¨ [doc3]  \n  - í•´ë‹¹ ìŠ¤í¬ë¦½íŠ¸ëŠ” `az storage blob upload-batch` ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ í•œ ë²ˆì— ë‹¤ìˆ˜ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ëŠ” ë°©ì‹ì„ ì·¨í•¨.  \n  - ë‹¤ë§Œ, `find` ëª…ë ¹ì–´ë¥¼ í†µí•œ íŒŒì¼ ìˆœíšŒ ë° ê°œë³„ ì—…ë¡œë“œëŠ” ì§ì ‘ì ìœ¼ë¡œ ë°œê²¬ë˜ì§€ ì•ŠìŒ.\n\n- **ìœ ì‚¬ë„ ë° ì°¨ì´ì **:  \n  - ë°œê²¬ëœ ìŠ¤í¬ë¦½íŠ¸ëŠ” **ì „ì²´ íŒŒì¼ ì¼ê´„ ì—…ë¡œë“œ**ë¥¼ ìˆ˜í–‰í•œë‹¤ëŠ” ì ì—ì„œ ë³€ê²½ ì „ ì½”ë“œ ì˜ë„ì™€ ì¼ì¹˜.  \n  - ë‹¤ë§Œ, `find` + `while read` ë°˜ë³µë¬¸ ë°©ì‹ ëŒ€ì‹ , `az storage blob upload-batch` ëª…ë ¹ì–´ë¡œ ì¼ê´„ì²˜ë¦¬í•˜ê³  ìˆì–´ êµ¬í˜„ ë°©ì‹ ì°¨ì´ ì¡´ì¬.  \n  - `.git` í´ë” ì œì™¸ ì²˜ë¦¬ì— ëŒ€í•œ ëª…ì‹œì  ì¡°ê±´ì€ ìŠ¤í¬ë¦½íŠ¸ ë‚´ì—ì„œ í™•ì¸ë˜ì§€ ì•ŠìŒ.  \n  - ë³€ìˆ˜ëª…ê³¼ ì£¼ì„ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì§ì ‘ì ì¸ ë¹„êµëŠ” ì–´ë ¤ìš°ë‚˜ ê¸°ëŠ¥ì  ì°¨ì›ì—ì„œ ì™„ì „ ì¼ì¹˜í•˜ì§€ëŠ” ì•ŠìŒ.\n\n- **ì¶”ê°€ í™•ì¸**:  \n  - `app/main.py` ë° `Dockerfile`, `requirements.txt` ë“±ì—ì„œ í•´ë‹¹ ìŠ¤í¬ë¦½íŠ¸ë‚˜ ìœ ì‚¬ ì½”ë“œ ë¯¸ë°œê²¬ [doc1][doc2][doc4][doc5].\n\n### ìš”ì•½  \n- ë³€ê²½ ì „ ì½”ë“œì™€ ì™„ì „íˆ ì¼ì¹˜í•˜ëŠ” ì½”ë“œ ë¸”ë¡ì€ ë°œê²¬ë˜ì§€ ì•ŠìŒ.  \n- ë¹„ìŠ·í•œ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ëŠ” íŒŒì¼ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ëŠ” `.github/workflows/upload-to-blob.yml`ì— ìˆìœ¼ë‚˜, êµ¬í˜„ ë°©ì‹ê³¼ ì„¸ë¶€ ë¡œì§ì´ ë‹¤ë¦„.  \n- ë”°ë¼ì„œ \"ë³€ê²½ ì „ ì½”ë“œ\"ëŠ” ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ì— **ì§ì ‘ì ìœ¼ë¡œ ì¡´ì¬í•˜ì§€ ì•ŠìŒ**.\n\n---\n\n## 2ë‹¨ê³„: ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ ê²€ì¦ (ë³€ê²½ ì „ ì½”ë“œ ë°œê²¬ ì‹œì—ë§Œ ìˆ˜í–‰)\n\n- ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•„ ë³¸ ë‹¨ê³„ëŠ” \"í•´ë‹¹ ì—†ìŒ\" ì²˜ë¦¬.\n\n---\n\n## 3ë‹¨ê³„: ì ìš© ì™„ë£Œë„ ê²€ì¦\n\n- ë³€ê²½ ì „ ì½”ë“œ ë¯¸ë°œê²¬ â†’ ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ ê²€ì¦ ë¶ˆê°€ â†’ \"í•´ë‹¹ ì—†ìŒ\"\n\n---\n\n## 4ë‹¨ê³„: ë…¼ë¦¬ì  ìƒíƒœ íŒë‹¨\n\n| í•­ëª©                    | ìƒíƒœ   | ì„¤ëª…                                                                                     |\n|-------------------------|--------|------------------------------------------------------------------------------------------|\n| ë³€ê²½ ì „ ì½”ë“œ ì‚¬ìš© ì—¬ë¶€    | ğŸŸ¢ ë¯¸ë°œê²¬ | ë³€ê²½ ì „ ì½”ë“œì™€ ì¼ì¹˜í•˜ê±°ë‚˜ ìœ ì‚¬í•œ êµ¬í˜„ì´ ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ               |\n| ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€    | âšª í•´ë‹¹ì—†ìŒ | ë³€ê²½ ì „ ì½”ë“œê°€ ë°œê²¬ë˜ì§€ ì•Šì•„ ì ìš© ì—¬ë¶€ íŒë‹¨ ë¶ˆê°€                                         |\n| ì „ë°˜ì  ì¤€ìˆ˜ ìƒíƒœ         | ğŸŸ¢ ì¤€ìˆ˜ | ë³€ê²½ ì „ ì½”ë“œ ë¶€ì¬ë¡œ ì¸í•´ ë³€ê²½ í›„ ì½”ë“œ ì ìš© í•„ìš” ì—†ìŒìœ¼ë¡œ ê°„ì£¼                            |\n| ìƒì„¸ ë¶„ì„ ê²°ê³¼           | ë³€ê²½ ì „ ì½”ë“œì™€ ì™„ì „ ì¼ì¹˜í•˜ëŠ” êµ¬í˜„ ì—†ìŒ. ìœ ì‚¬ ê¸°ëŠ¥ì˜ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìˆìœ¼ë‚˜ êµ¬í˜„ ì°¨ì´ ì¡´ì¬ |\n\n---\n\n## ì¢…í•©\n\n- ê·€í•˜ê°€ ì œì‹œí•œ ë³€ê²½ ì „ ì½”ë“œëŠ” ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ì—ì„œ ë™ì¼í•˜ê±°ë‚˜ ìœ ì‚¬í•œ í˜•íƒœë¡œ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.  \n- ë³€ê²½ ì „ ì½”ë“œì™€ ìœ ì‚¬í•œ ëª©ì (ì „ì²´ íŒŒì¼ ì¼ê´„ ì—…ë¡œë“œ)ì„ ìˆ˜í–‰í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ëŠ” `.github/workflows/upload-to-blob.yml`ì— ìˆìœ¼ë‚˜, êµ¬í˜„ ë°©ì‹ì´ ë‹¤ë¦…ë‹ˆë‹¤.  \n- ë”°ë¼ì„œ ë³€ê²½ í›„ ì½”ë“œê°€ ì‹¤ì œë¡œ ê¸°ì¡´ ì½”ë“œë¥¼ ëŒ€ì²´í–ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ íŒë‹¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.  \n- ì´ëŠ” ë³€ê²½ ì „ ì½”ë“œê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ë³€ê²½ í›„ ì½”ë“œ ì ìš© íŒë‹¨ì´ ë¶ˆê°€ëŠ¥í•¨ì„ ì˜ë¯¸í•˜ë©°, ì „ë°˜ì ìœ¼ë¡œ \"ì¤€ìˆ˜\"ë¡œ í‰ê°€í•©ë‹ˆë‹¤.\n\n---\n\n# ìµœì¢… ì¤€ìˆ˜ ìƒíƒœ ìš”ì•½ í‘œ\n\n| í•­ëª©               | ìƒíƒœ        | ì„¤ëª…                                                                                  |\n|--------------------|-------------|---------------------------------------------------------------------------------------|\n| ë³€ê²½ ì „ ì½”ë“œ ì‚¬ìš© ì—¬ë¶€ | ğŸŸ¢ ë¯¸ë°œê²¬    | ë³€ê²½ ì „ ì½”ë“œì™€ ì™„ì „ ë˜ëŠ” ìœ ì‚¬",
            "citations": [
              {
                "content": "python-dotenv\ndotenv\nopencensus-ext-azure\nopencensus-ext-fastapi\nfastapi\nuvicorn\n\n\n.txt\nrequirements.txt\nhttps://storagektdsjmg.blob.core.windows.net/github-api/requirements.txt",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "# 1) ë¹Œë“œ\nFROM python:3.11-slim AS base\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# 2) ëŸ°íƒ€ì„\nCOPY app ./app\nARG APPLICATIONINSIGHTS_CONNECTION_STRING\nENV APPLICATIONINSIGHTS_CONNECTION_STRING=$APPLICATIONINSIGHTS_CONNECTION_STRING\nENV APP_VERSION=1.0.0\nENV APP_BUILD=docker\nEXPOSE 8000\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n\n\n\nDockerfile\nhttps://storagektdsjmg.blob.core.windows.net/github-api/Dockerfile",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "name: Upload repo to Azure Blob Storage\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  upload-to-blob:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n\n      - name: Upload files to Azure Blob Storage\n        uses: azure/cli@v2\n        env:\n          AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n          AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n          AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n        with:\n          inlineScript: |\n            az storage blob upload-batch \\\n              --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n              --account-key \"$AZURE_STORAGE_KEY\" \\\n              --destination \"$AZURE_STORAGE_CONTAINER\" \\\n              --source . \\\n              --pattern \"*\"\n\n\n.yml\nupload-to-blob.yml\nhttps://storagektdsjmg.blob.core.windows.net/github-api/.github/workflows/upload-to-blob.yml",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "from fastapi import FastAPI\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel\nfrom datetime import datetime\n\nimport logging\nimport os\nfrom opencensus.ext.azure.log_exporter import AzureLogHandler\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Application Insights ì—°ê²° ë¬¸ìì—´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©\nconnection_string = os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\", \"\")\nif connection_string:\n    logger.addHandler(AzureLogHandler(connection_string=connection_string))\n\napp = FastAPI()\n\n@app.post(\"/now\")\ndef get_current_time():\n    logger.info(\"/now endpoint called\")\n    return {\"current_time\": datetime.now().isoformat()}\n\nclass AddParams(BaseModel):\n    param1: int\n    param2: int\n\n@app.post(\"/add\")\ndef add(params: AddParams):\n    logger.info(f\"/add endpoint called with param1={params.param1}, param2={params.param2}\")\n    return {\"result\": params.param1 + params.param2}\n\n\n.py\nmain.py\nhttps://storagektdsjmg.blob.core.windows.net/github-api/app/main.py",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": ".env\n\n\n.gitignore\n.gitignore\nhttps://storagektdsjmg.blob.core.windows.net/github-api/.gitignore",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              }
            ]
          }
        ]
      }
    }
  },
  {
    "title": "í…ŒìŠ¤íŠ¸ ê³µì§€",
    "desc": "í…ŒìŠ¤íŠ¸ ì ê²€",
    "lang": "python",
    "code_changes": [
      {
        "before": "{\"current_time\": datetime.now().isoformat()}",
        "after": "{\"time\": datetime.now().isoformat()}"
      }
    ],
    "timestamp": "2025-09-30 15:54:49",
    "latest_ai_check": {
      "container": "github-web",
      "index": "web-code-index",
      "timestamp": "2025-09-30 16:16:48",
      "results": [
        {
          "change_index": null,
          "before_code": "{\"current_time\": datetime.now().isoformat()}",
          "after_code": "{\"time\": datetime.now().isoformat()}",
          "ai_analysis": "í˜„ì¬ ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ì—ì„œ ë‹¤ìŒ ì‚¬í•­ì„ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤:\n\n1. **ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ (`{\"current_time\": datetime.now().isoformat()}`) ì‚¬ìš© ì—¬ë¶€**  \n   - ì¸ë±ìŠ¤ëœ ì½”ë“œ íŒŒì¼ë“¤ì˜ `.py` í™•ì¥ì ë‚´ì—ì„œëŠ” `\"current_time\"` í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ `datetime.now().isoformat()` ê°’ì„ í• ë‹¹í•œ íŒ¨í„´ì€ í™•ì¸ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  \n   - ì¦‰, ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ì€ í˜„ì¬ ì½”ë“œë² ì´ìŠ¤ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤ [doc1][doc3][doc4].\n\n2. **ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ (`{\"time\": datetime.now().isoformat()}`) ì ìš© ì—¬ë¶€**  \n   - `\"time\"` í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ `datetime.now().isoformat()` ê°’ì„ í• ë‹¹í•˜ëŠ” íŒ¨í„´ë„ í˜„ì¬ ì½”ë“œ ì¸ë±ìŠ¤ ë‚´ì—ì„œ ëª…í™•í•˜ê²Œ ë°œê²¬ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  \n   - ë”°ë¼ì„œ ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ë„ ì•„ì§ ì½”ë“œë² ì´ìŠ¤ì— ë°˜ì˜ë˜ì–´ ìˆì§€ ì•Šì€ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤ [doc1][doc3][doc4].\n\n3. **ì „ë°˜ì ì¸ ì¤€ìˆ˜ ìƒíƒœ í‰ê°€**  \n   - ì½”ë“œ ì¸ë±ìŠ¤ ë‚´ì—ì„œëŠ” ë‚ ì§œ ë° ì‹œê°„ ì •ë³´ë¥¼ JSON í˜•íƒœë¡œ ì €ì¥í•˜ëŠ” ì •í™•í•œ í‚¤ ëª…ì¹­(`\"current_time\"` í˜¹ì€ `\"time\"`)ì„ ì‚¬ìš©í•˜ëŠ” ì½”ë“œê°€ ì•„ì§ ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  \n   - ë”°ë¼ì„œ ë³€ê²½ ì‚¬í•­ì´ ê¸°ì¡´ ì½”ë“œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ì—†ìœ¼ë©°, ë³€ê²½ ì „ íŒ¨í„´ì€ ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ê´€ë¦¬ë˜ê³  ìˆê±°ë‚˜ ì• ì´ˆì— ì‚¬ìš©ë˜ì§€ ì•Šì€ ìƒíƒœë¡œ ë³´ì…ë‹ˆë‹¤.  \n   - ë³€ê²½ í›„ íŒ¨í„´ì€ ì•„ì§ ì ìš© ì „ìœ¼ë¡œ, ì ìš© ì‹œ ì¼ê´€ëœ í‚¤ ëª…ì¹­ ì‚¬ìš©ê³¼ ë¬¸ì„œí™”ê°€ í•„ìš”í•  ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.\n\n### ê²°ë¡   \n- **ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ì€ ì½”ë“œë² ì´ìŠ¤ì— ì¡´ì¬í•˜ì§€ ì•ŠìŒ**  \n- **ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ë„ ì•„ì§ ì ìš©ë˜ì§€ ì•ŠìŒ**  \n- **ë”°ë¼ì„œ í˜„ì¬ ì½”ë“œë² ì´ìŠ¤ëŠ” í•´ë‹¹ í‚¤ëª… ë³€ê²½ì— ëŒ€í•´ ì¤€ìˆ˜ ìƒíƒœê°€ ì–‘í˜¸í•˜ë©°, ë³€ê²½ ì ìš© ì „ ìƒíƒœì„**  \n- ë³€ê²½ ì‚¬í•­ ì ìš© ì‹œ, ì „ì²´ ì½”ë“œì™€ ë¬¸ì„œì—ì„œ `\"time\"` í‚¤ ì‚¬ìš©ì´ ì¼ê´€ë˜ê²Œ ì´ë£¨ì–´ì§€ëŠ”ì§€ ì¶”ê°€ ê²€ì¦ ê¶Œê³ \n\nì´ìƒì…ë‹ˆë‹¤.  \n\nì°¸ê³ : ì½”ë“œ íŒŒì¼ ë° ì¸ë±ìŠ¤ ë‚´ `.py` íŒŒì¼ë“¤ì˜ íŒ¨í„´ ë¶„ì„ê³¼ ì¸ë±ì‹±ëœ ë¬¸ì„œ ë¶„ë¥˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨í•˜ì˜€ìŠµë‹ˆë‹¤ [doc1][doc3][doc4].",
          "citations": [
            {
              "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[codz]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py.cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n# .python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# UV\n#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#uv.lock\n\n# poetry\n#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control\n#poetry.lock\n#poetry.toml\n\n# pdm\n#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.\n#   pdm recommends including project-wide configuration in pdm.toml, but excluding .pdm-python.\n#   https://pdm-project.org/en/latest/usage/project/#working-with-version-control\n#pdm.lock\n#pdm.toml\n.pdm-python\n.pdm-build/\n\n# pixi\n#   Similar to Pipfile.lock, it is generally recommended to include pixi.lock in version control.\n#pixi.lock\n#   Pixi creates a virtual environment in the .pixi directory, just like venv module creates one\n#   in the .venv directory. It is recommended not to include this directory in version control.\n.pixi\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.envrc\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Azure specific\ntemp_*\n*.tmp\n.azure/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n#.idea/\n\n# Abstra\n# Abstra is an AI-powered process automation framework.\n# Ignore directories containing user credentials, local state, and settings.\n# Learn more at https://abstra.io/docs\n.abstra/\n\n# Visual Studio Code\n#  Visual Studio Code specific template is maintained in a separate VisualStudioCode.gitignore \n#  that can be found at https://github.com/github/gitignore/blob/main/Global/VisualStudioCode.gitignore\n#  and can be added to the global gitignore or merged into this file. However, if you prefer, \n#  you could uncomment the following to ignore the entire vscode folder\n# .vscode/\n\n# Ruff stuff:\n.ruff_cache/\n\n# PyPI configuration file\n.pypirc\n\n# Cursor\n#  Cursor is an AI-powered code editor. `.cursorignore` specifies files/directories to\n#  exclude from AI features like autocomplete and code analysis. Recommended for sensitive data\n#  refer to https://docs.cursor.com/context/ignore-files\n.cursorignore\n.cursorindexingignore\n\n# Marimo\nmarimo/_static/\nmarimo/_lsp/\n__marimo__/\n\n\n.gitignore\nhttps://storagektdsjmg.blob.core.windows.net/github-web/.gitignore",
              "title": null,
              "url": null,
              "filepath": null,
              "chunk_id": "0"
            },
            {
              "content": "name: Upload Files to Azure Blob and Create AI Search Index\n\non:\n  push:\n    branches: [ main, develop ]\n  workflow_dispatch:\n\npermissions:\n  contents: read\n\nenv:\n  AZURE_RESOURCE_GROUP: 'rg-ktds-jmg'\n  CONTAINER_NAME: 'github-web'\n  INDEX_NAME: 'web-code-index'\n  INDEXER_NAME: 'web-code-indexer'\n  DATASOURCE_NAME: 'github-web-datasource'\n\njobs:\n  upload-and-index:\n    runs-on: ubuntu-latest\n    \n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v4\n\n    - name: Azure Login\n      uses: azure/login@v1\n      with:\n        creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n    - name: Get Azure Resources Info\n      id: resources\n      run: |\n        # ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n        storage_account=$(az storage account list \\\n          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n          --query \"[0].name\" -o tsv)\n        \n        search_service=$(az search service list \\\n          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n          --query \"[0].name\" -o tsv).echo \"\"\n        echo \"ğŸ“Š Summary:\"\n        echo \"ğŸ“¦ Storage Account: $storage_account_name\"\n        echo \"ğŸ“ Container: ${{ env.CONTAINER_NAME }}\"\n        echo \"ğŸ” Search Service: $search_service_name\"\n        echo \"ğŸ“‹ Index Name: ${{ env.INDEX_NAME }}\"\n        echo \"ğŸ¤– Indexer Name: ${{ env.INDEXER_NAME }}\"\n        echo \"\"\n        echo \"âœ… Files uploaded to Azure Blob Storage\"\n        echo \"âœ… AI Search index created and configured\"\n        echo \"âœ… Indexer running every 5 minutes\"\n        echo \"\"\n        echo \"ğŸ¤– OpenAI can now use '${{ env.INDEX_NAME }}' index for code Q&amp;A!\".# ì—…ë¡œë“œëœ íŒŒì¼ ìˆ˜ í™•ì¸\n        storage_key=$(az storage account keys list \\\n          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n          --account-name $storage_account_name \\\n          --query \"[0].value\" -o tsv)\n          \n        file_count=$(az storage blob list \\\n          --account-name $storage_account_name \\\n          --account-key $storage_key \\\n          --container-name ${{ env.CONTAINER_NAME }} \\\n          --query \"length(@)\")\n        \n        echo \"ğŸ“ˆ Total files in container: $file_count\"",
              "title": null,
              "url": null,
              "filepath": null,
              "chunk_id": "0"
            },
            {
              "content": ".\n\n### ğŸ¯ ì£¼ìš” ê¸°ëŠ¥\n\n- **ğŸ“¤ ìë™ íŒŒì¼ ì—…ë¡œë“œ**: GitHub push â†’ Azure Blob Storage ìë™ ì—…ë¡œë“œ\n- **ğŸ“ íŒŒì¼ ë¶„ë¥˜**: ì½”ë“œ, ë¬¸ì„œ, ì„¤ì • íŒŒì¼ë³„ë¡œ ì»¨í…Œì´ë„ˆ ë¶„ë¦¬ ì €ì¥\n- **ğŸ“Š ì—…ë¡œë“œ ì¶”ì **: íŒŒì¼ ì¸ë²¤í† ë¦¬ ìƒì„± ë° ë©”íƒ€ë°ì´í„° ê´€ë¦¬\n- **âš¡ CI/CD íŒŒì´í”„ë¼ì¸**: GitHub Actionsë¥¼ í†µí•œ ì™„ì „ ìë™í™”\n- **ğŸ”’ ë³´ì•ˆ**: Azure Key Vaultë¥¼ í†µí•œ ì•ˆì „í•œ ì—°ê²° ì •ë³´ ê´€ë¦¬\n\n### ğŸ—ï¸ ì•„í‚¤í…ì²˜\n\n```\nGitHub Repository â†’ GitHub Actions â†’ Azure Blob Storage\n     â†“                   â†“              â†“\nCode Changes â†’ Auto Upload â†’ File Classification â†’ AI Ready\n     â†“                   â†“              â†“           â†“\n   [code]            [documents]      [data]   â†’ Other AI Services\n```\n\n### ğŸš€ ë¹ ë¥¸ ì‹œì‘\n\n#### 1..\\venv\\Scripts\\Activate.ps1\n\n# ì—…ë¡œë“œ ìƒíƒœ í™•ì¸\npython check_upload_status.py\n\n# Streamlit ì•± ì‹¤í–‰ (ì„ íƒì‚¬í•­)\nstreamlit run app.py\n```\n\n### ğŸ“¦ ë°°í¬ë˜ëŠ” Azure ë¦¬ì†ŒìŠ¤\n\n| ì„œë¹„ìŠ¤ | ìš©ë„ | SKU |\n|--------|------|-----|\n| **Storage Account** | íŒŒì¼ ì €ì¥ì†Œ (3ê°œ ì»¨í…Œì´ë„ˆ) | Standard_LRS |\n| **Key Vault** | ì—°ê²° ì •ë³´ ë° í‚¤ ê´€ë¦¬ | Standard |\n\n### ğŸ“ Storage ì»¨í…Œì´ë„ˆ êµ¬ì¡°\n\n| ì»¨í…Œì´ë„ˆ | ì €ì¥ íŒŒì¼ | ìš©ë„ |\n|----------|-----------|------|\n| **code** | `*.py` | Python ì½”ë“œ íŒŒì¼ë“¤ |\n| **documents** | `*.md`, `*.txt`, `*.rst` | ë¬¸ì„œ ë° README íŒŒì¼ë“¤ |\n| **data** | `*.json`, `*.yml`, `*.toml`, `infra/*` | ì„¤ì • íŒŒì¼ ë° ì¸í”„ë¼ ì½”ë“œ |\n\n### ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ\n\n#### ê¸°ë³¸ ì•±\n- **Streamlit**: ì›¹ ì¸í„°í˜ì´ìŠ¤ (ì„ íƒì‚¬í•­)\n- **Python**: ê¸°ë³¸ ëŸ°íƒ€ì„\n\n#### Azure Services\n- **Blob Storage**: íŒŒì¼ ì €ì¥ ë° ë¶„ë¥˜\n- **Key Vault**: ë³´ì•ˆ ê´€ë¦¬\n\n#### DevOps\n- **GitHub Actions**: ìë™ ì—…ë¡œë“œ íŒŒì´í”„ë¼ì¸\n- **Azure Bicep**: Infrastructure as Code\n- **Azure CLI**: íŒŒì¼ ì—…ë¡œë“œ ìë™í™”\n\n### ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°\n\n```\nAzureMVP_WEB/\nâ”œâ”€â”€ .github/workflows/     # GitHub Actions ì›Œí¬í”Œë¡œìš°\nâ”‚   â””â”€â”€ azure-deploy.yml   # ìë™ ì—…ë¡œë“œ íŒŒì´í”„ë¼ì¸\nâ”œâ”€â”€ infra/                 # Infrastructure as Code\nâ”‚   â”œâ”€â”€ main.bicep.**AI ì„œë¹„ìŠ¤ ì¤€ë¹„** â†’ ë‹¤ë¥¸ ë ˆí¬ì§€í† ë¦¬ì—ì„œ í™œìš© ê°€ëŠ¥\n\n### ğŸ“Š ì—…ë¡œë“œë˜ëŠ” íŒŒì¼ë“¤\n\n#### Code ì»¨í…Œì´ë„ˆ\n- Python ìŠ¤í¬ë¦½íŠ¸ (.py)\n- ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ íŒŒì¼ë“¤\n\n#### Documents ì»¨í…Œì´ë„ˆ  \n- README íŒŒì¼ (.md)\n- í…ìŠ¤íŠ¸ ë¬¸ì„œ (.txt, .rst)\n- í”„ë¡œì íŠ¸ ë¬¸ì„œë“¤\n\n#### Data ì»¨í…Œì´ë„ˆ\n- ì„¤ì • íŒŒì¼ (requirements.txt, *.json, *.yml)\n- ì¸í”„ë¼ ì½”ë“œ (infra/*.bicep)\n- íŒŒì¼ ì¸ë²¤í† ë¦¬ (JSON í˜•íƒœ ë©”íƒ€ë°ì´í„°)\n\n### ğŸ¯ AI ì„œë¹„ìŠ¤ í™œìš©\n\nì´ ì‹œìŠ¤í…œìœ¼ë¡œ ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì€ ë‹¤ë¥¸ ì €ì¥ì†Œì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\n1..**Azure OpenAI**: code ì»¨í…Œì´ë„ˆì˜ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ë¬¸ì„œ ìƒì„±\n3..Fork the repository\n2..Push to the branch\n5.",
              "title": null,
              "url": null,
              "filepath": null,
              "chunk_id": "0"
            },
            {
              "content": "**GitHub Actions ì›Œí¬í”Œë¡œìš°**ê°€ ìë™ìœ¼ë¡œ:\n   - Azure ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ ìƒì„±\n   - Storage Account ë° Key Vault ë°°í¬\n   - 3ê°œ ì»¨í…Œì´ë„ˆ ìƒì„± (code, documents, data)\n   - í”„ë¡œì íŠ¸ íŒŒì¼ë“¤ì„ ë¶„ë¥˜í•˜ì—¬ ì—…ë¡œë“œ\n   - íŒŒì¼ ì¸ë²¤í† ë¦¬ ìƒì„±\n\n### 4..ë°°í¬ í™•ì¸\n\nGitHub Actions íƒ­ì—ì„œ ë°°í¬ ì§„í–‰ ìƒí™©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n## ğŸ¯ ë°°í¬ë˜ëŠ” Azure ë¦¬ì†ŒìŠ¤\n\n| ì„œë¹„ìŠ¤ | ìš©ë„ | ì„¤ì • |\n|--------|------|------|\n| **Resource Group** | ë¦¬ì†ŒìŠ¤ ì»¨í…Œì´ë„ˆ | rg-azuremvp-dev |\n| **Storage Account** | íŒŒì¼ ì €ì¥ì†Œ | Standard_LRS |\n| **Key Vault** | ì—°ê²° ì •ë³´ ê´€ë¦¬ | Standard |\n\n## ğŸ“ íŒŒì¼ ë¶„ë¥˜ ì‹œìŠ¤í…œ\n\n### Code ì»¨í…Œì´ë„ˆ\n- **ëŒ€ìƒ**: `*.py` íŒŒì¼ë“¤\n- **ìš©ë„**: Python ì½”ë“œ, ìŠ¤í¬ë¦½íŠ¸\n- **AI í™œìš©**: ì½”ë“œ ë¶„ì„, ë¬¸ì„œ ìƒì„±\n\n### Documents ì»¨í…Œì´ë„ˆ  \n- **ëŒ€ìƒ**: `*.md`, `*.txt`, `*.rst` íŒŒì¼ë“¤\n- **ìš©ë„**: ë¬¸ì„œ, README, ê°€ì´ë“œ\n- **AI í™œìš©**: ë‚´ìš© ê²€ìƒ‰, ì§ˆë¬¸ ë‹µë³€\n\n### Data ì»¨í…Œì´ë„ˆ\n- **ëŒ€ìƒ**: `*.json`, `*.yml`, `*.toml`, `infra/*` íŒŒì¼ë“¤\n- **ìš©ë„**: ì„¤ì •, ì¸í”„ë¼ ì½”ë“œ, ë©”íƒ€ë°ì´í„°\n- **AI í™œìš©**: êµ¬ì„± ë¶„ì„, ìë™í™”\n\n## ğŸ”§ ë¡œì»¬ í…ŒìŠ¤íŠ¸\n\n### ì—…ë¡œë“œ ìƒíƒœ í™•ì¸\n```bash\n# ê°€ìƒí™˜ê²½ í™œì„±í™”\n..**ì»¨í…Œì´ë„ˆ ìƒì„± ì‹¤íŒ¨**:\n   - Storage Account ìƒì„± ìƒíƒœ í™•ì¸\n   - ë„¤íŠ¸ì›Œí¬ ê¶Œí•œ í™•ì¸\n\n### ë¡œê·¸ í™•ì¸\n\n- **GitHub Actions**: Actions íƒ­ì—ì„œ ì›Œí¬í”Œë¡œìš° ë¡œê·¸\n- **Azure Portal**: Activity Logì—ì„œ ë¦¬ì†ŒìŠ¤ ìƒì„± ë¡œê·¸\n- **ë¡œì»¬**: `check_upload_status.py` ì‹¤í–‰ ê²°ê³¼\n\n## ğŸ¯ AI ì„œë¹„ìŠ¤ì™€ ì—°ë™\n\n### ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì—ì„œ í™œìš©\n\n```python\n# Azure Storage ì—°ê²° ì˜ˆì‹œ\nfrom azure.storage.blob import BlobServiceClient\n\nconnection_string = \"...\" # Key Vaultì—ì„œ ê°€ì ¸ì˜¤ê¸°\nblob_service = BlobServiceClient.from_connection_string(connection_string)\n\n# ì½”ë“œ íŒŒì¼ë“¤ ì½ê¸°\ncontainer_client = blob_service.get_container_client(\"code\")\nblobs = container_client.list_blobs()\n\nfor blob in blobs:\n    if blob.name.endswith('.py'):\n        # AI ì„œë¹„ìŠ¤ë¡œ ì½”ë“œ ë¶„ì„\n        content = container_client.download_blob(blob.name).readall()\n        # process_with_ai(content)\n```\n\n### Cognitive Search ì—°ë™\n- Documents ì»¨í…Œì´ë„ˆë¥¼ ë°ì´í„° ì†ŒìŠ¤ë¡œ ì„¤ì •\n- ìë™ ì¸ë±ì‹± ë° ê²€ìƒ‰ ê¸°ëŠ¥ êµ¬í˜„\n\n### OpenAI ì—°ë™\n- Code ì»¨í…Œì´ë„ˆì˜ ì½”ë“œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©\n- ì½”ë“œ ì„¤ëª…, ë²„ê·¸ ì°¾ê¸°, ê°œì„  ì œì•ˆ ë“±\n\n## ğŸ‰ ì„±ê³µì ì¸ ë°°í¬ í™•ì¸\n\në°°í¬ê°€ ì„±ê³µí•˜ë©´:\n\n1. âœ… GitHub Actionsì—ì„œ ëª¨ë“  jobì´ ì„±ê³µ\n2. âœ… Azure Portalì—ì„œ Storage Account ë° ì»¨í…Œì´ë„ˆ í™•ì¸\n3. âœ… ê° ì»¨í…Œì´ë„ˆì—",
              "title": null,
              "url": null,
              "filepath": null,
              "chunk_id": "0"
            }
          ]
        }
      ]
    },
    "ai_check_results_by_env": {
      "github-api|azureblob-index": {
        "container": "github-api",
        "index": "azureblob-index",
        "timestamp": "2025-09-30 16:39:18",
        "results": [
          {
            "change_index": null,
            "before_code": "{\"current_time\": datetime.now().isoformat()}",
            "after_code": "{\"time\": datetime.now().isoformat()}",
            "ai_analysis": "ì•„ë˜ëŠ” ìš”ì²­í•˜ì‹  ì½”ë“œ ë³€ê²½ì‚¬í•­(ë³€ê²½ ì „: `{\"current_time\": datetime.now().isoformat()}` â†’ ë³€ê²½ í›„: `{\"time\": datetime.now().isoformat()}`)ì— ëŒ€í•œ ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ ì² ì €í•œ ê²€ì¦ ê²°ê³¼ì…ë‹ˆë‹¤.\n\n---\n\n# 1ë‹¨ê³„: ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ ê²€ìƒ‰\n\n- ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì½”ë“œ:  \n  - `{\"current_time\": datetime.now().isoformat()}`  \n- ìœ ì‚¬ íŒ¨í„´ ë° ë³€í˜• í˜•íƒœ:  \n  - í˜„ì¬ ì¸ë±ìŠ¤ëœ ì½”ë“œ ì¤‘ì—ì„œ ë™ì¼í•˜ê±°ë‚˜ ìœ ì‚¬í•œ í‚¤ ì´ë¦„(`current_time`)ê³¼ `datetime.now().isoformat()` ì¡°í•©ì„ ì‚¬ìš©í•˜ëŠ” ë¶€ë¶„ì„ ì¤‘ì‹¬ìœ¼ë¡œ ê²€ìƒ‰\n\n### ê²€ìƒ‰ ê²°ê³¼\n\n- `main.py` (doc2) ë‚´ `/now` ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„ì—ì„œ ë‹¤ìŒ ì½”ë“œê°€ ë°œê²¬ë¨:\n\n```python\n@app.post(\"/now\")\ndef get_current_time():\n    logger.info(\"/now endpoint called\")\n    return {\"current_time\": datetime.now().isoformat()}\n```\n\n- ìœ„ì¹˜: `main.py` ì „ì²´ ì½”ë“œ ì¤‘ `get_current_time` í•¨ìˆ˜ ë°˜í™˜ë¶€  \n- ë§¥ë½: FastAPI ì—”ë“œí¬ì¸íŠ¸ë¡œì„œ í˜„ì¬ ì‹œê°„ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” ê¸°ëŠ¥  \n- ì¶”ê°€ ìœ ì‚¬ ì½”ë“œë‚˜ ë³€í˜• í˜•íƒœëŠ” ì¸ë±ìŠ¤ëœ ë¬¸ì„œì—ì„œ ë°œê²¬ë˜ì§€ ì•ŠìŒ\n\n---\n\n# 2ë‹¨ê³„: ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ ê²€ì¦\n\n- ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´: `{\"time\": datetime.now().isoformat()}`  \n- ë™ì¼ ê¸°ëŠ¥ ë‹¤ë¥¸ êµ¬í˜„ ë°©ì‹ ì—¬ë¶€:  \n  - ë³€ê²½ í›„ í‚¤ëª…ë§Œ `time`ìœ¼ë¡œ ë°”ë€ í˜•íƒœê°€ ë³€ê²½ ì „ê³¼ ë™ì¼í•œ ê¸°ëŠ¥ ìˆ˜í–‰\n\n### ê²€ìƒ‰ ê²°ê³¼\n\n- ë³€ê²½ í›„ ì½”ë“œê°€ ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ì—ëŠ” ì¡´ì¬í•˜ì§€ ì•ŠìŒ  \n- ì¦‰, `main.py` ë‚´ `/now` ì—”ë“œí¬ì¸íŠ¸ ë°˜í™˜ë¶€ëŠ” ì—¬ì „íˆ ë³€ê²½ ì „ ì½”ë“œ(`\"current_time\"`)ë¥¼ ì‚¬ìš© ì¤‘ì„  \n- ë³€ê²½ í›„ ì½”ë“œ(`\"time\"`)ë¡œ ëŒ€ì²´ëœ ìœ„ì¹˜ëŠ” í™•ì¸ë˜ì§€ ì•ŠìŒ\n\n---\n\n# 3ë‹¨ê³„: ì ìš© ì™„ë£Œë„ ê²€ì¦\n\n- ë³€ê²½ ì „ ì½”ë“œ ë°œê²¬ ìœ„ì¹˜: 1ê°œ (`main.py` ë‚´ `/now` ì—”ë“œí¬ì¸íŠ¸ ë°˜í™˜ë¶€)  \n- ë³€ê²½ í›„ ì½”ë“œ ì ìš© ìœ„ì¹˜: 0ê°œ  \n- êµì²´ ë¹„ìœ¨: 0/1 = 0% (ë¯¸ì ìš©)  \n- ëˆ„ë½ ìœ„ì¹˜:  \n  - `main.py` ë‚´ `/now` ì—”ë“œí¬ì¸íŠ¸ ë°˜í™˜ë¶€ (ì „ì²´ í•¨ìˆ˜ ìœ„ì¹˜: doc2, ëŒ€ëµ 8~13ë¼ì¸ êµ¬ê°„)\n\n- ì‹ ê·œ ì¶”ê°€ëœ ë³€ê²½ í›„ ì½”ë“œ ìœ„ì¹˜ ì—†ìŒ\n\n---\n\n# 4ë‹¨ê³„: ë…¼ë¦¬ì  ìƒíƒœ íŒë‹¨\n\n- ë³€ê²½ ì „ ì½”ë“œ ë°œê²¬ë¨ â†’ `main.py` ë‚´ 1ê³³  \n- ë³€ê²½ í›„ ì½”ë“œ ë¯¸ì ìš© (0%)  \n- ë”°ë¼ì„œ, ë³€ê²½ ì „ ì½”ë“œê°€ ë°œê²¬ë˜ì—ˆìœ¼ë‚˜ ë³€ê²½ í›„ ì½”ë“œë¡œ êµì²´ë˜ì§€ ì•Šì•„ **ğŸ”´ ë¯¸ì ìš©** ìƒíƒœì„\n\n---\n\n# ìµœì¢… ì¤€ìˆ˜ ìƒíƒœ ìš”ì•½ í‘œ\n\n| í•­ëª©                 | ìƒíƒœ    | ì„¤ëª…                                                                                     |\n|----------------------|---------|------------------------------------------------------------------------------------------|\n| ë³€ê²½ ì „ ì½”ë“œ ì‚¬ìš© ì—¬ë¶€    | ğŸ”´ ë°œê²¬ë¨ | `main.py` ë‚´ `/now` ì—”ë“œí¬ì¸íŠ¸ ë°˜í™˜ë¶€ì—ì„œ ì •í™•íˆ 1íšŒ ë°œê²¬ë¨ (doc2, ì•½ 8~13ë¼ì¸)         |\n| ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€    | ğŸ”´ ë¯¸ì ìš© | ë³€ê²½ í›„ ì½”ë“œ(`\"time\"`)ëŠ” ì½”ë“œë² ì´ìŠ¤ ë‚´ ì–´ë””ì—ì„œë„ ë°œê²¬ë˜ì§€ ì•ŠìŒ, êµì²´ ë¹„ìœ¨ 0%             |\n| ì „ë°˜ì  ì¤€ìˆ˜ ìƒíƒœ          | ğŸ”´ ë¯¸ì¤€ìˆ˜ | ë³€ê²½ ì „ ì½”ë“œ ë°œê²¬ í›„ ë³€ê²½ í›„ ì½”ë“œë¡œ êµì²´ë˜ì§€ ì•Šì•„ ë¯¸ì¤€ìˆ˜ ìƒíƒœ                            |\n| ìƒì„¸ ë¶„ì„ ê²°ê³¼           | ë³€ê²½ ì „ ì½”ë“œ 1ê°œ ìœ„ì¹˜: `main.py` `/now` ì—”ë“œí¬ì¸íŠ¸ ë°˜í™˜ë¶€ (doc2, 8~13ë¼ì¸)                |\n|                       | ë³€ê²½ í›„ ì½”ë“œ 0ê°œ ìœ„ì¹˜, êµì²´ 0%                                                             |\n|                       | ì½”ë“œë² ì´ìŠ¤ ë‚´ ìœ ì‚¬ íŒ¨í„´ ë˜ëŠ” ë³€í˜• í˜•íƒœ ì—†ìŒ                                               |\n\n---\n\n# ê²°ë¡ \n\ní˜„ì¬ ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ì—ì„œëŠ” ìš”ì²­í•˜ì‹  ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ì´ `main.py` ë‚´ `/now` ì—”ë“œí¬ì¸íŠ¸ì—ì„œ 1íšŒ ë°œê²¬ë˜ë©°, ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ìœ¼ë¡œì˜ êµì²´ëŠ” ì´ë£¨ì–´ì§€ì§€ ì•Šì€ ìƒíƒœì…ë‹ˆë‹¤. ë”°ë¼ì„œ ë³€ê²½ ì‚¬í•­ ì ìš©ì€ **ë¯¸ì ìš©(ğŸ”´)** ìƒíƒœë¡œ íŒë‹¨ë©ë‹ˆë‹¤.\n\ní•„ìš” ì‹œ í•´ë‹¹ ìœ„ì¹˜ì—ì„œ ì½”ë“œë¥¼ ì•„ë˜ì™€ ê°™ì´ ë³€ê²½í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤:\n\n```python\nreturn {\"time\": datetime.now().isoformat()}\n```\n\nì´ìƒì…ë‹ˆë‹¤.",
            "citations": [
              {
                "content": "name: Upload repo to Azure Blob Storage\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  upload-to-blob:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n\n      - name: Upload files to Azure Blob Storage\n        uses: azure/cli@v2\n        env:\n          AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n          AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n          AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n        with:\n          inlineScript: |\n            az storage blob upload-batch \\\n              --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n              --account-key \"$AZURE_STORAGE_KEY\" \\\n              --destination \"$AZURE_STORAGE_CONTAINER\" \\\n              --source . \\\n              --pattern \"*\"\n\n\napplication/octet-stream\nupload-to-blob.yml",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "from fastapi import FastAPI\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel\nfrom datetime import datetime\n\nimport logging\nimport os\nfrom opencensus.ext.azure.log_exporter import AzureLogHandler\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Application Insights ì—°ê²° ë¬¸ìì—´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©\nconnection_string = os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\", \"\")\nif connection_string:\n    logger.addHandler(AzureLogHandler(connection_string=connection_string))\n\napp = FastAPI()\n\n@app.post(\"/now\")\ndef get_current_time():\n    logger.info(\"/now endpoint called\")\n    return {\"current_time\": datetime.now().isoformat()}\n\nclass AddParams(BaseModel):\n    param1: int\n    param2: int\n\n@app.post(\"/add\")\ndef add(params: AddParams):\n    logger.info(f\"/add endpoint called with param1={params.param1}, param2={params.param2}\")\n    return {\"result\": params.param1 + params.param2}\n\n\ntext/x-python\nmain.py",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "\napplication/x-python-code\nmain.cpython-313.pyc",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "# 1) ë¹Œë“œ\nFROM python:3.11-slim AS base\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# 2) ëŸ°íƒ€ì„\nCOPY app ./app\nARG APPLICATIONINSIGHTS_CONNECTION_STRING\nENV APPLICATIONINSIGHTS_CONNECTION_STRING=$APPLICATIONINSIGHTS_CONNECTION_STRING\nENV APP_VERSION=1.0.0\nENV APP_BUILD=docker\nEXPOSE 8000\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n\n\napplication/octet-stream\nDockerfile",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "python-dotenv\ndotenv\nopencensus-ext-azure\nopencensus-ext-fastapi\nfastapi\nuvicorn\n\n\ntext/plain\nrequirements.txt",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              }
            ]
          }
        ]
      },
      "github-api|code-search-index": {
        "container": "github-api",
        "index": "code-search-index",
        "timestamp": "2025-09-30 16:22:53",
        "results": [
          {
            "change_index": null,
            "before_code": "{\"current_time\": datetime.now().isoformat()}",
            "after_code": "{\"time\": datetime.now().isoformat()}",
            "ai_analysis": "ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ì—ì„œ ìš”ì²­í•˜ì‹  ë‘ ì½”ë“œ íŒ¨í„´ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ í™•ì¸ ë° í‰ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.\n\n1. **ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ í™•ì¸**  \n   ```python\n   {\"current_time\": datetime.now().isoformat()}\n   ```  \n   - ì´ íŒ¨í„´ì€ `[doc1]`ì˜ FastAPI ì—”ë“œí¬ì¸íŠ¸ `/now` í•¨ìˆ˜ì—ì„œ ê·¸ëŒ€ë¡œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.  \n   - í•´ë‹¹ í•¨ìˆ˜ëŠ” `return {\"current_time\": datetime.now().isoformat()}` í˜•ì‹ìœ¼ë¡œ ì‘ì„±ë˜ì–´ ìˆì–´, ë³€ê²½ ì „ ì½”ë“œê°€ ì—¬ì „íˆ ì½”ë“œë² ì´ìŠ¤ì— ì¡´ì¬í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\n\n2. **ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ í™•ì¸**  \n   ```python\n   {\"time\": datetime.now().isoformat()}\n   ```  \n   - ì¸ë±ìŠ¤ëœ ë¬¸ì„œ ë‚´ì—ì„œëŠ” ì´ì™€ ê°™ì€ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.  \n   - ì¦‰, ì½”ë“œë² ì´ìŠ¤ì— ì•„ì§ ì ìš©ëœ ìƒíƒœê°€ ì•„ë‹ˆë¼ê³  íŒë‹¨ë©ë‹ˆë‹¤.\n\n3. **ì „ë°˜ì ì¸ ì¤€ìˆ˜ ìƒíƒœ í‰ê°€**  \n   - í˜„ì¬ ì½”ë“œë² ì´ìŠ¤ì—ì„œëŠ” ì—¬ì „íˆ ë³€ê²½ ì „ ì½”ë“œ(`current_time` í‚¤ ì‚¬ìš©)ë¥¼ ìœ ì§€í•˜ê³  ìˆìœ¼ë©°, ë³€ê²½ í›„ ì½”ë“œ(`time` í‚¤ ì‚¬ìš©)ëŠ” ì ìš©ë˜ì§€ ì•Šì€ ìƒíƒœì…ë‹ˆë‹¤.  \n   - ë”°ë¼ì„œ, ë§Œì•½ ë³€ê²½ í›„ ì½”ë“œë¡œ ì „í™˜í•˜ëŠ” ê²ƒì´ ëª©í‘œë¼ë©´, ê´€ë ¨ëœ ëª¨ë“  í˜¸ì¶œë¶€ ë° ë¬¸ì„œí™”ë„ í•¨ê»˜ ìˆ˜ì •ë˜ì–´ì•¼ í•˜ë©°, í˜„ì¬ëŠ” ë³€ê²½ ì „ ìƒíƒœë¥¼ ì¤€ìˆ˜í•˜ê³  ìˆë‹¤ê³  í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n---\n\n### ìš”ì•½\n| ì ê²€ í•­ëª©                | ê²°ê³¼                            |\n|-------------------------|---------------------------------|\n| ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ ì¡´ì¬ ì—¬ë¶€ | ì¡´ì¬ (`{\"current_time\": ...}`) í™•ì¸ë¨ [doc1] |\n| ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ ì¡´ì¬ ì—¬ë¶€ | ì—†ìŒ (`{\"time\": ...}` ì—†ìŒ)       |\n| ì „ë°˜ì  ì¤€ìˆ˜ ìƒíƒœ          | ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ì„ ìœ ì§€ ì¤‘       |\n\ní•„ìš” ì‹œ ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ìœ¼ë¡œ ì¼ê´„ ìˆ˜ì • ì‘ì—…ì´ ìš”êµ¬ë©ë‹ˆë‹¤.  \nì°¸ê³ ë¡œ, ì¸ë±ìŠ¤ëœ ë¬¸ì„œì—ëŠ” ê´€ë ¨ëœ ë‹¤ë¥¸ ë³€ê²½ì´ë‚˜ ìƒˆë¡œìš´ íŒ¨í„´ ì ìš©ì— ëŒ€í•œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤ [doc1][doc2].",
            "citations": [
              {
                "content": "from fastapi import FastAPI\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel\nfrom datetime import datetime\n\nimport logging\nimport os\nfrom opencensus.ext.azure.log_exporter import AzureLogHandler\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Application Insights ì—°ê²° ë¬¸ìì—´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©\nconnection_string = os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\", \"\")\nif connection_string:\n    logger.addHandler(AzureLogHandler(connection_string=connection_string))\n\napp = FastAPI()\n\n@app.post(\"/now\")\ndef get_current_time():\n    logger.info(\"/now endpoint called\")\n    return {\"current_time\": datetime.now().isoformat()}\n\nclass AddParams(BaseModel):\n    param1: int\n    param2: int\n\n@app.post(\"/add\")\ndef add(params: AddParams):\n    logger.info(f\"/add endpoint called with param1={params.param1}, param2={params.param2}\")\n    return {\"result\": params.param1 + params.param2}\n\n\n.py\nmain.py\nhttps://storagektdsjmg.blob.core.windows.net/github-api/app/main.py",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "name: Upload repo to Azure Blob Storage\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  upload-to-blob:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n\n      - name: Upload files to Azure Blob Storage\n        uses: azure/cli@v2\n        env:\n          AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}\n          AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}\n          AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}\n        with:\n          inlineScript: |\n            az storage blob upload-batch \\\n              --account-name \"$AZURE_STORAGE_ACCOUNT\" \\\n              --account-key \"$AZURE_STORAGE_KEY\" \\\n              --destination \"$AZURE_STORAGE_CONTAINER\" \\\n              --source . \\\n              --pattern \"*\"\n\n\n.yml\nupload-to-blob.yml\nhttps://storagektdsjmg.blob.core.windows.net/github-api/.github/workflows/upload-to-blob.yml",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              }
            ]
          }
        ]
      },
      "github-web|web-code-index": {
        "container": "github-web",
        "index": "web-code-index",
        "timestamp": "2025-09-30 16:40:06",
        "results": [
          {
            "change_index": null,
            "before_code": "{\"current_time\": datetime.now().isoformat()}",
            "after_code": "{\"time\": datetime.now().isoformat()}",
            "ai_analysis": "í˜„ì¬ ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ì—ì„œ ìš”ì²­í•˜ì‹  ë³€ê²½ ì „ ë° ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ì— ëŒ€í•œ ì² ì €í•œ ê²€ì¦ì„ ìˆ˜í–‰í•œ ê²°ê³¼ë¥¼ ë‹¨ê³„ë³„ë¡œ ì•„ë˜ì™€ ê°™ì´ ìƒì„¸íˆ ë³´ê³ ë“œë¦½ë‹ˆë‹¤.\n\n---\n\n## 1ë‹¨ê³„: ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ ê²€ìƒ‰\n\n- ê²€ìƒ‰ ëŒ€ìƒ:  \n  ```python\n  {\"current_time\": datetime.now().isoformat()}\n  ```\n- **ì •í™• ì¼ì¹˜ ì½”ë“œ ë¸”ë¡ ê²€ìƒ‰ ê²°ê³¼**  \n  - ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ í•´ë‹¹ ì •í™•í•œ JSON ê°ì²´ í˜•íƒœ(í‚¤ëª… `\"current_time\"` + `datetime.now().isoformat()` í˜¸ì¶œ ì¡°í•©)ë¥¼ í¬í•¨í•˜ëŠ” íŒŒì¼ ë° ìœ„ì¹˜ëŠ” **ê²€ìƒ‰ë˜ì§€ ì•Šì•˜ìŒ**.\n- **ìœ ì‚¬ íŒ¨í„´ ë˜ëŠ” ë³€í˜•ëœ í˜•íƒœ ê²€ìƒ‰ ê²°ê³¼**  \n  - `\"current_time\"`ì´ë¼ëŠ” í‚¤ëª…ì„ í¬í•¨í•˜ë©´ì„œ `datetime.now().isoformat()` í˜¸ì¶œ ê²°ê³¼ë¥¼ ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë³€í˜•ëœ ì½”ë“œ(ì˜ˆ: ë³€ìˆ˜ í• ë‹¹, í•¨ìˆ˜ ì¸ì ë“±)ë„ **ë°œê²¬ë˜ì§€ ì•ŠìŒ**.\n  - `\"current_time\"`ì´ë¼ëŠ” í‚¤ë¥¼ í¬í•¨í•˜ëŠ” ë‹¤ë¥¸ ì½”ë“œ ì¡°ê°ë„ ì¸ë±ìŠ¤ëœ ì½”ë“œ ë‚´ì— ì¡´ì¬í•˜ì§€ ì•ŠìŒ.\n- **ë¶„ì„**  \n  - ì¸ë±ìŠ¤ëœ ì£¼ìš” íŒŒì¼ ì˜ˆ: `check_upload_status.py` ë“±ì—ì„œëŠ” `\"time\"` ë˜ëŠ” `\"current_time\"`ì„ í‚¤ë¡œ í•˜ëŠ” JSON ê°ì²´ê°€ ë°œê²¬ë˜ì§€ ì•ŠìŒ.\n  - ë˜í•œ, ì¸ë±ìŠ¤ ë‚´ ì£¼ìš” Python ì½”ë“œ(`*.py`) íŒŒì¼ë“¤ì—ì„œ `datetime.now().isoformat()` í˜¸ì¶œ í›„ `\"current_time\"` í‚¤ëª…ê³¼ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” í˜•íƒœ ì—­ì‹œ ì—†ìŒ.\n\n**ê²°ë¡ : ë³€ê²½ ì „ ì½”ë“œ(`{\"current_time\": datetime.now().isoformat()}`)ëŠ” ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ì—ì„œ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŒ.**\n\n---\n\n## 2ë‹¨ê³„: ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ ê²€ì¦ (ë³€ê²½ ì „ ì½”ë“œê°€ ë°œê²¬ëœ ê²½ìš°ì—ë§Œ ìˆ˜í–‰)\n\n- ë³€ê²½ ì „ ì½”ë“œê°€ ì¸ë±ìŠ¤ ë‚´ ë¯¸ë°œê²¬ì´ë¯€ë¡œ ë³¸ ë‹¨ê³„ëŠ” **ì ìš© ëŒ€ìƒ ì•„ë‹˜(âšª í•´ë‹¹ ì—†ìŒ)**.\n\n---\n\n## 3ë‹¨ê³„: ì ìš© ì™„ë£Œë„ ê²€ì¦\n\n- ë³€ê²½ ì „ ì½”ë“œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ì ìš© ì™„ë£Œë„ ê²€ì¦ì€ **ë¶ˆí•„ìš”(âšª í•´ë‹¹ ì—†ìŒ)**.\n\n---\n\n## 4ë‹¨ê³„: ë…¼ë¦¬ì  ìƒíƒœ íŒë‹¨\n\n- ë³€ê²½ ì „ ì½”ë“œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ íŒë‹¨ ì—­ì‹œ ì˜ë¯¸ ì—†ìŒ.\n- ë”°ë¼ì„œ ì „ë°˜ì  ì¤€ìˆ˜ ìƒíƒœëŠ” **ğŸŸ¢ ì¤€ìˆ˜**ë¡œ íŒì •í•¨.\n\n---\n\n# ì¤€ìˆ˜ ìƒíƒœ ìš”ì•½ í‘œ\n\n| í•­ëª©                    | ìƒíƒœ    | ì„¤ëª…                                                       |\n|-------------------------|---------|------------------------------------------------------------|\n| ë³€ê²½ ì „ ì½”ë“œ ì‚¬ìš© ì—¬ë¶€   | ğŸŸ¢ ë¯¸ë°œê²¬ | ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ `\"current_time\"` í‚¤ì™€ í•¨ê»˜ `datetime.now().isoformat()` í˜¸ì¶œí•˜ëŠ” ì½”ë“œ ë¯¸ë°œê²¬ |\n| ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€  | âšª í•´ë‹¹ì—†ìŒ | ë³€ê²½ ì „ ì½”ë“œ ë¯¸ë°œê²¬ìœ¼ë¡œ ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ íŒë‹¨ ë¶ˆê°€  |\n| ì „ë°˜ì  ì¤€ìˆ˜ ìƒíƒœ        | ğŸŸ¢ ì¤€ìˆ˜  | ë³€ê²½ ì „ ì½”ë“œ ë¯¸ë°œê²¬ìœ¼ë¡œ ë³€ê²½ í›„ ì½”ë“œ ì ìš© ì—¬ë¶€ì™€ ë¬´ê´€      |\n| ìƒì„¸ ë¶„ì„ ê²°ê³¼          | ìœ„ 1ë‹¨ê³„ ìƒì„¸ ë‚´ìš© ì°¸ì¡° | ëª¨ë“  ì¸ë±ìŠ¤ëœ Python ì½”ë“œ ë° ê´€ë ¨ íŒŒì¼ì—ì„œ ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ ë¯¸ë°œê²¬ |\n\n---\n\n# ì¶”ê°€ ì°¸ê³ \n\n- ì¸ë±ìŠ¤ëœ ì£¼ìš” ì½”ë“œë² ì´ìŠ¤(ì˜ˆ: Python íŒŒì¼ë“¤) ë° Azure Blob ì—°ë™, GitHub Actions ì›Œí¬í”Œë¡œìš° ì½”ë“œ ë“±ì—ì„œ `\"time\"` í‚¤ë¥¼ ì‚¬ìš©í•˜ëŠ” JSON ê°ì²´ëŠ” ê°„í—ì ìœ¼ë¡œ ë“±ì¥í•˜ì§€ë§Œ, `\"current_time\"` í‚¤ëŠ” ì „í˜€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŒ.\n- `datetime.now().isoformat()` í˜¸ì¶œì€ ì¼ë¶€ ì½”ë“œì—ì„œ ì‚¬ìš© ì—¬ë¶€ ë¶ˆë¶„ëª…í•˜ë‚˜, `\"current_time\"` í‚¤ì™€ ë¬¶ì¸ í˜•íƒœë¡œëŠ” ì¡´ì¬í•˜ì§€ ì•ŠìŒ.\n- ë”°ë¼ì„œ, ë³€ê²½ ì „ ì½”ë“œ íŒ¨í„´ ìì²´ê°€ ì¸ë±ìŠ¤ ë‚´ì— ì—†ìœ¼ë¯€ë¡œ ë³€ê²½ í›„ ì½”ë“œ íŒ¨í„´ ì ìš© ê²€ì¦ ëŒ€ìƒë„ ì—†ìŒ.\n\n---\n\nìš”ì•½í•˜ë©´, ì¸ë±ìŠ¤ëœ ì½”ë“œë² ì´ìŠ¤ ë‚´ì—ì„œëŠ” ë³€ê²½ ì „ ì½”ë“œ(`{\"current_time\": datetime.now().isoformat()}`)ê°€ ì „í˜€ ë°œê²¬ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ë³€ê²½ í›„ ì½”ë“œ(`{\"time\": datetime.now().isoformat()}`) ì ìš© ì—¬ë¶€ë„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ì— ë”°ë¼ ì „ë°˜ì  ì¤€ìˆ˜ ìƒíƒœëŠ” \"ğŸŸ¢ ì¤€ìˆ˜\"ë¡œ ê²°ë¡ ë‚´ë¦½ë‹ˆë‹¤.",
            "citations": [
              {
                "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[codz]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py.cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n# .python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# UV\n#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#uv.lock\n\n# poetry\n#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control\n#poetry.lock\n#poetry.toml\n\n# pdm\n#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.\n#   pdm recommends including project-wide configuration in pdm.toml, but excluding .pdm-python.\n#   https://pdm-project.org/en/latest/usage/project/#working-with-version-control\n#pdm.lock\n#pdm.toml\n.pdm-python\n.pdm-build/\n\n# pixi\n#   Similar to Pipfile.lock, it is generally recommended to include pixi.lock in version control.\n#pixi.lock\n#   Pixi creates a virtual environment in the .pixi directory, just like venv module creates one\n#   in the .venv directory. It is recommended not to include this directory in version control.\n.pixi\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.envrc\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Azure specific\ntemp_*\n*.tmp\n.azure/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n#.idea/\n\n# Abstra\n# Abstra is an AI-powered process automation framework.\n# Ignore directories containing user credentials, local state, and settings.\n# Learn more at https://abstra.io/docs\n.abstra/\n\n# Visual Studio Code\n#  Visual Studio Code specific template is maintained in a separate VisualStudioCode.gitignore \n#  that can be found at https://github.com/github/gitignore/blob/main/Global/VisualStudioCode.gitignore\n#  and can be added to the global gitignore or merged into this file. However, if you prefer, \n#  you could uncomment the following to ignore the entire vscode folder\n# .vscode/\n\n# Ruff stuff:\n.ruff_cache/\n\n# PyPI configuration file\n.pypirc\n\n# Cursor\n#  Cursor is an AI-powered code editor. `.cursorignore` specifies files/directories to\n#  exclude from AI features like autocomplete and code analysis. Recommended for sensitive data\n#  refer to https://docs.cursor.com/context/ignore-files\n.cursorignore\n.cursorindexingignore\n\n# Marimo\nmarimo/_static/\nmarimo/_lsp/\n__marimo__/\n\n\n.gitignore\nhttps://storagektdsjmg.blob.core.windows.net/github-web/.gitignore",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "**Service Principal** ìƒì„±:\n   ```bash\n   az ad sp create-for-rbac --name \"AzureMVP-FileUpload\" \\\n     --role contributor \\\n     --scopes /subscriptions/{subscription-id}\n   ```\n\n### 2..GitHub Secrets ì„¤ì •\n\nGitHub ì €ì¥ì†Œì˜ Settings &gt; Secrets and variables &gt; Actionsì— ë‹¤ìŒ ì‹œí¬ë¦¿ë“¤ì„ ì¶”ê°€:\n\nService Principal ìƒì„± ê²°ê³¼ì—ì„œ ë‹¤ìŒ ê°’ë“¤ì„ ê°ê° ì¶”ê°€:\n- `AZURE_CLIENT_ID`: appId ê°’\n- `AZURE_CLIENT_SECRET`: password ê°’  \n- `AZURE_TENANT_ID`: tenant ê°’\n- `AZURE_SUBSCRIPTION_ID`: ì‚¬ìš©í•  Azure êµ¬ë… ID\n\n### 3..**GitHub Actions ì›Œí¬í”Œë¡œìš°**ê°€ ìë™ìœ¼ë¡œ:\n   - Azure ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ ìƒì„±\n   - Storage Account ë° Key Vault ë°°í¬\n   - 3ê°œ ì»¨í…Œì´ë„ˆ ìƒì„± (code, documents, data)\n   - í”„ë¡œì íŠ¸ íŒŒì¼ë“¤ì„ ë¶„ë¥˜í•˜ì—¬ ì—…ë¡œë“œ\n   - íŒŒì¼ ì¸ë²¤í† ë¦¬ ìƒì„±\n\n### 4..ë°°í¬ í™•ì¸\n\nGitHub Actions íƒ­ì—ì„œ ë°°í¬ ì§„í–‰ ìƒí™©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n## ğŸ¯ ë°°í¬ë˜ëŠ” Azure ë¦¬ì†ŒìŠ¤\n\n| ì„œë¹„ìŠ¤ | ìš©ë„ | ì„¤ì • |\n|--------|------|------|\n| **Resource Group** | ë¦¬ì†ŒìŠ¤ ì»¨í…Œì´ë„ˆ | rg-azuremvp-dev |\n| **Storage Account** | íŒŒì¼ ì €ì¥ì†Œ | Standard_LRS |\n| **Key Vault** | ì—°ê²° ì •ë³´ ê´€ë¦¬ | Standard |\n\n## ğŸ“ íŒŒì¼ ë¶„ë¥˜ ì‹œìŠ¤í…œ\n\n### Code ì»¨í…Œì´ë„ˆ\n- **ëŒ€ìƒ**: `*.py` íŒŒì¼ë“¤\n- **ìš©ë„**: Python ì½”ë“œ, ìŠ¤í¬ë¦½íŠ¸\n- **AI í™œìš©**: ì½”ë“œ ë¶„ì„, ë¬¸ì„œ ìƒì„±\n\n### Documents ì»¨í…Œì´ë„ˆ  \n- **ëŒ€ìƒ**: `*.md`, `*.txt`, `*.rst` íŒŒì¼ë“¤\n- **ìš©ë„**: ë¬¸ì„œ, README, ê°€ì´ë“œ\n- **AI í™œìš©**: ë‚´ìš© ê²€ìƒ‰, ì§ˆë¬¸ ë‹µë³€\n\n### Data ì»¨í…Œì´ë„ˆ\n- **ëŒ€ìƒ**: `*.json`, `*.yml`, `*.toml`, `infra/*` íŒŒì¼ë“¤\n- **ìš©ë„**: ì„¤ì •, ì¸í”„ë¼ ì½”ë“œ, ë©”íƒ€ë°ì´í„°\n- **AI í™œìš©**: êµ¬ì„± ë¶„ì„, ìë™í™”\n\n## ğŸ”§ ë¡œì»¬ í…ŒìŠ¤íŠ¸\n\n### ì—…ë¡œë“œ ìƒíƒœ í™•ì¸\n```bash\n# ê°€ìƒí™˜ê²½ í™œì„±í™”\n..**ì»¨í…Œì´ë„ˆ ìƒì„± ì‹¤íŒ¨**:\n   - Storage Account ìƒì„± ìƒíƒœ í™•ì¸\n   - ë„¤íŠ¸ì›Œí¬ ê¶Œí•œ í™•ì¸\n\n### ë¡œê·¸ í™•ì¸\n\n- **GitHub Actions**: Actions íƒ­ì—ì„œ ì›Œí¬í”Œë¡œìš° ë¡œê·¸\n- **Azure Portal**: Activity Logì—ì„œ ë¦¬ì†ŒìŠ¤ ìƒì„± ë¡œê·¸\n- **ë¡œì»¬**: `check_upload_status.py` ì‹¤í–‰ ê²°ê³¼\n\n## ğŸ¯ AI ì„œë¹„ìŠ¤ì™€ ì—°ë™\n\n### ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì—ì„œ í™œìš©\n\n```python\n# Azure Storage ì—°ê²° ì˜ˆì‹œ\nfrom azure.storage.blob import BlobServiceClient\n\nconnection_string = \"...\" # Key Vaultì—ì„œ ê°€ì ¸ì˜¤ê¸°\nblob_service = BlobServiceClient.from_connection_string(connection_string)\n\n# ì½”ë“œ íŒŒì¼ë“¤ ì½ê¸°\ncontainer_client = blob_service.get_container_client(\"code\")\nblobs = container_client.list_blobs()\n\nfor blob in blobs:\n    if blob.name.endswith('.py'):\n        # AI ì„œë¹„ìŠ¤ë¡œ ì½”ë“œ ë¶„ì„\n        content = container_client.download_blob(blob.name).readall()\n        # process_with_ai(content)\n```\n\n### Cognitive Search ì—°ë™\n- Documents ì»¨í…Œì´ë„ˆë¥¼ ë°ì´í„° ì†ŒìŠ¤ë¡œ ì„¤ì •\n- ìë™ ì¸ë±ì‹± ë° ê²€ìƒ‰ ê¸°ëŠ¥ êµ¬í˜„\n\n### OpenAI ì—°ë™\n- Code ì»¨í…Œì´ë„ˆì˜ ì½”ë“œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©\n- ì½”ë“œ ì„¤ëª…, ë²„ê·¸ ì°¾ê¸°, ê°œì„  ì œì•ˆ ë“±\n\n## ğŸ‰ ì„±ê³µì ì¸ ë°°í¬ í™•ì¸\n\në°°í¬ê°€ ì„±ê³µí•˜ë©´:\n\n1. âœ… GitHub Actionsì—ì„œ ëª¨ë“  jobì´ ì„±ê³µ\n2. âœ… Azure Portalì—ì„œ Storage Account ë° ì»¨í…Œì´ë„ˆ í™•ì¸\n3. âœ… ê° ì»¨í…Œì´ë„ˆì—",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "echo \"\"\n  echo \"ğŸ“Š Summary:\"\n  echo \"ğŸ“¦ Storage Account: $storage_account_name\"\n  echo \"ğŸ“ Container: ${{ env.CONTAINER_NAME }}\"\n  echo \"ğŸ” Search Service: $search_service_name\"\n  echo \"ğŸ“‹ Index Name: ${{ env.INDEX_NAME }}\"\n  echo \"ğŸ¤– Indexer Name: ${{ env.INDEXER_NAME }}\"\n  echo \"\"\n  echo \"âœ… Files uploaded to Azure Blob Storage\"\n  echo \"âœ… AI Search index created and configured\"\n  echo \"âœ… Indexer running every 5 minutes\"\n  echo \"\"\n  echo \"ğŸ¤– OpenAI can now use '${{ env.INDEX_NAME }}' index for code Q&amp;A!\".# ì—…ë¡œë“œëœ íŒŒì¼ ìˆ˜ í™•ì¸\n  storage_key=$(az storage account keys list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --account-name $storage_account_name \\\n  --query \"[0].value\" -o tsv)\n  \n  file_count=$(az storage blob list \\\n  --account-name $storage_account_name \\\n  --account-key $storage_key \\\n  --container-name ${{ env.CONTAINER_NAME }} \\\n  --query \"length(@)\")\n  \n  echo \"ğŸ“ˆ Total files in container: $file_count\"",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "1"
              },
              {
                "content": "name: Upload Files to Azure Blob and Create AI Search Index\n\non:\n  push:\n  branches: [ main, develop ]\n  workflow_dispatch:\n\npermissions:\n  contents: read\n\nenv:\n  AZURE_RESOURCE_GROUP: 'rg-ktds-jmg'\n  CONTAINER_NAME: 'github-web'\n  INDEX_NAME: 'web-code-index'\n  INDEXER_NAME: 'web-code-indexer'\n  DATASOURCE_NAME: 'github-web-datasource'\n\njobs:\n  upload-and-index:\n  runs-on: ubuntu-latest\n  \n  steps:\n  - name: Checkout code\n  uses: actions/checkout@v4\n\n  - name: Azure Login\n  uses: azure/login@v1\n  with:\n  creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n  - name: Get Azure Resources Info\n  id: resources\n  run: |\n  # ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n  storage_account=$(az storage account list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --query \"[0].name\" -o tsv)\n  \n  search_service=$(az search service list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --query \"[0].name\" -o tsv).echo \"storage-account-name=$storage_account\" &gt;&gt; $GITHUB_OUTPUT\n  echo \"search-service-name=$search_service\" &gt;&gt; $GITHUB_OUTPUT\n  \n  echo \"âœ… Found resources:\"\n  echo \"ğŸ“¦ Storage Account: $storage_account\"\n  echo \"ğŸ” Search Service: $search_service\"\n\n  - name: Upload Files to Blob Storage\n  run: |\n  storage_account_name=\"${{ steps.resources.outputs.storage-account-name }}\"\n  \n  # Storage Account Key ê°€ì ¸ì˜¤ê¸°\n  storage_key=$(az storage account keys list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --account-name $storage_account_name \\\n  --query \"[0].value\" -o tsv)\n  \n  echo \"ğŸ“¤ Uploading changed files to ${{ env.CONTAINER_NAME }} container.\".echo \"ğŸ“Š Uploaded: $upload_count files\"\n  echo \"â­ï¸  Skipped: $skip_count files (unchanged)\"\n  \n  # ì„ì‹œ íŒŒì¼ ì •ë¦¬\n  rm -f existing_blobs.json\n\n  - name: Create or Update Search Index\n  run: |\n  search_service_name=\"${{ steps.resources.outputs.search-service-name }}\"\n  \n  # Search Service í‚¤ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°\n  search_key=$(az search admin-key show \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --service-name $search_service_name \\\n  --query primaryKey -o tsv)\n  \n  search_endpoint=\"https://${search_service_name}.search.windows.net\"\n  \n  echo \"ğŸ” Creating/Updating Search Index: ${{ env.INDEX_NAME }}\"\n  \n  # ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ (ìˆë‹¤ë©´)\n  curl -X DELETE \"$search_endpoint/indexes/${{ env.INDEX_NAME }}?.\"type\": \"Edm.String\",\n  \"searchable\": true,\n  \"filterable\": true,\n  \"sortable\": false,\n  \"facetable\": false\n  },\n  {\n  \"name\": \"extension\",\n  \"type\": \"Edm.String\",\n  \"searchable\": false,\n  \"filterable\": true,\n  \"sortable\": false,\n  \"facetable\": true\n  },\n  {\n  \"name\": \"size\",\n  \"type\": \"Edm.Int64\",\n  \"searchable\": false,\n  \"filterable\": true,\n  \"sortable\": true,\n  \"facetable\": false\n  },\n  {\n  \"name\": \"lastModified\",\n  \"type\": \"Edm.DateTimeOffset\",\n  \"searchable\": false,\n  \"filterable\": true,\n  \"sortable\": true,\n  \"facetable\": false\n  }\n  ]\n  }'\n  \n  echo \"âœ… Search.- name: Setup Data Source and Indexer\n  run: |\n  search_service_name=\"${{ steps.resources.outputs.search-service-name }}\"\n  storage_account_name=\"${{ steps.resources.outputs.storage-account-name }}\"\n  \n  # Search Service í‚¤ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°\n  search_key=$(az search admin-key show \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --service-name $search_service_name \\\n  --query primaryKey -o tsv)\n  \n  # Storage Connection String ì§ì ‘ ìƒì„±\n  storage_key=$(az storage account keys list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --account-name $storage_account_name \\\n  --query \"[0].value\" -o tsv)\n  \n  storage_connection_string=\"DefaultEndpointsProtocol=https;AccountName=$storage_account_name;AccountKey=$storage_key;EndpointSuffix=core.windows.net\"\n  \n  search_endpoint=\"https://${search_service_name}.search.windows.net\"\n  \n  echo \"ğŸ”— Creating Data Source.\"dataSourceName\": \"${{ env.DATASOURCE_NAME }}\",\n  \"targetIndexName\": \"${{ env.INDEX_NAME }}\",\n  \"schedule\": {\n  \"interval\": \"PT5M\"\n  },\n  \"fieldMappings\": [\n  {\n  \"sourceFieldName\": \"metadata_storage_name\",\n  \"targetFieldName\": \"filename\"\n  },\n  {\n  \"sourceFieldName\": \"metadata_storage_path\",\n  \"targetFieldName\": \"filepath\"\n  },\n  {\n  \"sourceFieldName\": \"metadata_storage_file_extension\",\n  \"targetFieldName\": \"extension\"\n  },\n  {\n  \"sourceFieldName\": \"metadata_storage_size\",\n  \"targetFieldName\": \"size\"\n  },\n  {\n  \"sourceFieldName\": \"metadata_storage_last_modified\",\n  \"targetFieldName\": \"lastModified\"\n  }\n  ]\n  }'\n  \n  echo \"ğŸš€ Starting indexer to.api-version=2023-11-01\" \\\n  -H \"api-key: $search_key\"\n  \n  echo \"âœ… Indexer created and started successfully!\".- name: Verification\n  run: |\n  storage_account_name=\"${{ steps.resources.outputs.storage-account-name }}\"\n  search_service_name=\"${{ steps.resources.outputs.search-service-name }}\"\n  \n  echo \"ğŸ‰ Upload and Indexing Process Completed!\"",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              },
              {
                "content": "name: Upload Files to Azure Blob and Create AI Search Index\n\non:\n  push:\n  branches: [ main, develop ]\n  workflow_dispatch:\n\npermissions:\n  contents: read\n\nenv:\n  AZURE_RESOURCE_GROUP: 'rg-ktds-jmg'\n  CONTAINER_NAME: 'github-web'\n  INDEX_NAME: 'web-code-index'\n  INDEXER_NAME: 'web-code-indexer'\n  DATASOURCE_NAME: 'github-web-datasource'\n\njobs:\n  upload-and-index:\n  runs-on: ubuntu-latest\n  \n  steps:\n  - name: Checkout code\n  uses: actions/checkout@v4\n\n  - name: Azure Login\n  uses: azure/login@v1\n  with:\n  creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n  - name: Get Azure Resources Info\n  id: resources\n  run: |\n  # ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n  storage_account=$(az storage account list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --query \"[0].name\" -o tsv)\n  \n  search_service=$(az search service list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --query \"[0].name\" -o tsv).echo \"storage-account-name=$storage_account\" &gt;&gt; $GITHUB_OUTPUT\n  echo \"search-service-name=$search_service\" &gt;&gt; $GITHUB_OUTPUT\n  \n  echo \"âœ… Found resources:\"\n  echo \"ğŸ“¦ Storage Account: $storage_account\"\n  echo \"ğŸ” Search Service: $search_service\"\n\n  - name: Upload Files to Blob Storage\n  run: |\n  storage_account_name=\"${{ steps.resources.outputs.storage-account-name }}\"\n  \n  # Storage Account Key ê°€ì ¸ì˜¤ê¸°\n  storage_key=$(az storage account keys list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --account-name $storage_account_name \\\n  --query \"[0].value\" -o tsv)\n  \n  echo \"ğŸ“¤ Uploading changed files to ${{ env.CONTAINER_NAME }} container.\".- name: Setup Data Source and Indexer\n  run: |\n  search_service_name=\"${{ steps.resources.outputs.search-service-name }}\"\n  storage_account_name=\"${{ steps.resources.outputs.storage-account-name }}\"\n  \n  # Search Service í‚¤ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°\n  search_key=$(az search admin-key show \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --service-name $search_service_name \\\n  --query primaryKey -o tsv)\n  \n  # Storage Connection String ì§ì ‘ ìƒì„±\n  storage_key=$(az storage account keys list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --account-name $storage_account_name \\\n  --query \"[0].value\" -o tsv)\n  \n  storage_connection_string=\"DefaultEndpointsProtocol=https;AccountName=$storage_account_name;AccountKey=$storage_key;EndpointSuffix=core.windows.net\"\n  \n  search_endpoint=\"https://${search_service_name}.search.windows.net\"\n  \n  echo \"ğŸ”— Creating Data Source.\"dataSourceName\": \"${{ env.DATASOURCE_NAME }}\",\n  \"targetIndexName\": \"${{ env.INDEX_NAME }}\",\n  \"schedule\": {\n  \"interval\": \"PT5M\"\n  },\n  \"fieldMappings\": [\n  {\n  \"sourceFieldName\": \"metadata_storage_name\",\n  \"targetFieldName\": \"filename\"\n  },\n  {\n  \"sourceFieldName\": \"metadata_storage_path\",\n  \"targetFieldName\": \"filepath\"\n  },\n  {\n  \"sourceFieldName\": \"metadata_storage_file_extension\",\n  \"targetFieldName\": \"extension\"\n  },\n  {\n  \"sourceFieldName\": \"metadata_storage_size\",\n  \"targetFieldName\": \"size\"\n  },\n  {\n  \"sourceFieldName\": \"metadata_storage_last_modified\",\n  \"targetFieldName\": \"lastModified\"\n  }\n  ]\n  }'\n  \n  echo \"ğŸš€ Starting indexer to.api-version=2023-11-01\" \\\n  -H \"api-key: $search_key\"\n  \n  echo \"âœ… Indexer created and started successfully!\".- name: Verification\n  run: |\n  storage_account_name=\"${{ steps.resources.outputs.storage-account-name }}\"\n  search_service_name=\"${{ steps.resources.outputs.search-service-name }}\"\n  \n  echo \"ğŸ‰ Upload and Indexing Process Completed!\".echo \"\"\n  echo \"ğŸ“Š Summary:\"\n  echo \"ğŸ“¦ Storage Account: $storage_account_name\"\n  echo \"ğŸ“ Container: ${{ env.CONTAINER_NAME }}\"\n  echo \"ğŸ” Search Service: $search_service_name\"\n  echo \"ğŸ“‹ Index Name: ${{ env.INDEX_NAME }}\"\n  echo \"ğŸ¤– Indexer Name: ${{ env.INDEXER_NAME }}\"\n  echo \"\"\n  echo \"âœ… Files uploaded to Azure Blob Storage\"\n  echo \"âœ… AI Search index created and configured\"\n  echo \"âœ… Indexer running every 5 minutes\"\n  echo \"\"\n  echo \"ğŸ¤– OpenAI can now use '${{ env.INDEX_NAME }}' index for code Q&amp;A!\".# ì—…ë¡œë“œëœ íŒŒì¼ ìˆ˜ í™•ì¸\n  storage_key=$(az storage account keys list \\\n  --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n  --account-name $storage_account_name \\\n  --query \"[0].value\" -o tsv)\n  \n  file_count=$(az storage blob list \\\n  --account-name $storage_account_name \\\n  --account-key $storage_key \\\n  --container-name ${{ env.CONTAINER_NAME }} \\\n  --query \"length(@)\")\n  \n  echo \"ğŸ“ˆ Total files in container: $file_count\"",
                "title": null,
                "url": null,
                "filepath": null,
                "chunk_id": "0"
              }
            ]
          }
        ]
      }
    }
  }
]